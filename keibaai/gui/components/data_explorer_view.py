"""
ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ©ãƒ¼ãƒ“ãƒ¥ãƒ¼: å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã®è©³ç´°è¡¨ç¤º
"""

import streamlit as st
import pandas as pd
from pathlib import Path
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).resolve().parent.parent.parent.parent
sys.path.insert(0, str(project_root))


def render_data_explorer():
    """ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ©ãƒ¼ã®ãƒ¡ã‚¤ãƒ³è¡¨ç¤º"""

    st.title("ðŸ” ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ©ãƒ¼")

    st.markdown("""
    å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’è©³ã—ãç¢ºèªã§ãã¾ã™ã€‚
    å®Ÿéš›ã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã€é¦¬ãƒ‡ãƒ¼ã‚¿ã€è¡€çµ±ãƒ‡ãƒ¼ã‚¿ãªã©ã‚’é–²è¦§ãƒ»æ¤œç´¢ã§ãã¾ã™ã€‚
    """)

    st.markdown("---")

    # ã‚¿ãƒ–ã§å„ãƒ‡ãƒ¼ã‚¿ç¨®é¡žã‚’åˆ†ã‘ã‚‹
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ðŸ‡ ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿",
        "ðŸ´ é¦¬ãƒ‡ãƒ¼ã‚¿",
        "ðŸ§¬ è¡€çµ±ãƒ‡ãƒ¼ã‚¿",
        "ðŸ“‹ å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿",
        "ðŸ“Š çµ±è¨ˆæƒ…å ±"
    ])

    with tab1:
        render_races_explorer()

    with tab2:
        render_horses_explorer()

    with tab3:
        render_pedigrees_explorer()

    with tab4:
        render_shutuba_explorer()

    with tab5:
        render_statistics()


def render_races_explorer():
    """ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ©ãƒ¼"""

    st.markdown("### ðŸ‡ ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿")

    races_parquet = project_root / "keibaai" / "data" / "parsed" / "parquet" / "races" / "races.parquet"

    if not races_parquet.exists():
        st.warning("âš ï¸ ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    try:
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        df = pd.read_parquet(races_parquet)

        st.success(f"âœ… {len(df):,}ä»¶ã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        col1, col2, col3 = st.columns(3)

        with col1:
            if "venue" in df.columns:
                venues = ["ã™ã¹ã¦"] + sorted(df["venue"].dropna().unique().tolist())
                selected_venue = st.selectbox("ç«¶é¦¬å ´", venues, key="race_venue_filter")

        with col2:
            if "race_date" in df.columns:
                df["race_date"] = pd.to_datetime(df["race_date"], errors='coerce')
                min_date = df["race_date"].min()
                max_date = df["race_date"].max()

                if pd.notna(min_date) and pd.notna(max_date):
                    date_range = st.date_input(
                        "æ—¥ä»˜ç¯„å›²",
                        value=(min_date, max_date),
                        key="race_date_filter"
                    )

        with col3:
            if "track_surface" in df.columns:
                surfaces = ["ã™ã¹ã¦"] + sorted(df["track_surface"].dropna().unique().tolist())
                selected_surface = st.selectbox("é¦¬å ´", surfaces, key="race_surface_filter")

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é©ç”¨
        filtered_df = df.copy()

        if selected_venue != "ã™ã¹ã¦":
            filtered_df = filtered_df[filtered_df["venue"] == selected_venue]

        if selected_surface != "ã™ã¹ã¦":
            filtered_df = filtered_df[filtered_df["track_surface"] == selected_surface]

        if "race_date" in df.columns and len(date_range) == 2:
            filtered_df = filtered_df[
                (filtered_df["race_date"] >= pd.Timestamp(date_range[0])) &
                (filtered_df["race_date"] <= pd.Timestamp(date_range[1]))
            ]

        st.info(f"ðŸ“Š ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(filtered_df):,}ä»¶")

        # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºï¼ˆæœ€åˆã®100ä»¶ï¼‰
        st.markdown("#### ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€æ–°100ä»¶ï¼‰")

        display_cols = [
            "race_id", "race_date", "venue", "race_name",
            "track_surface", "distance_m", "weather", "track_condition",
            "head_count", "prize_1st"
        ]

        # å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã®ã¿é¸æŠž
        available_cols = [col for col in display_cols if col in filtered_df.columns]

        st.dataframe(
            filtered_df[available_cols].head(100),
            use_container_width=True,
            hide_index=True
        )

        # ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.markdown("#### ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        csv_data = filtered_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="ðŸ“¥ CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_data,
            file_name="races_data.csv",
            mime="text/csv"
        )

        # ã‚«ãƒ©ãƒ æƒ…å ±
        with st.expander("ðŸ“‹ ã‚«ãƒ©ãƒ æƒ…å ±"):
            col_info = []
            for col in filtered_df.columns:
                col_info.append({
                    "ã‚«ãƒ©ãƒ å": col,
                    "ãƒ‡ãƒ¼ã‚¿åž‹": str(filtered_df[col].dtype),
                    "æ¬ ææ•°": filtered_df[col].isna().sum(),
                    "ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°": filtered_df[col].nunique()
                })

            st.dataframe(pd.DataFrame(col_info), use_container_width=True, hide_index=True)

    except Exception as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")


def render_horses_explorer():
    """é¦¬ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ©ãƒ¼"""

    st.markdown("### ðŸ´ é¦¬ãƒ‡ãƒ¼ã‚¿")

    horses_parquet = project_root / "keibaai" / "data" / "parsed" / "parquet" / "horses" / "horses.parquet"

    if not horses_parquet.exists():
        st.warning("âš ï¸ é¦¬ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    try:
        df = pd.read_parquet(horses_parquet)

        st.success(f"âœ… {len(df):,}é ­ã®é¦¬ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")

        # æ¤œç´¢æ©Ÿèƒ½
        search_term = st.text_input("ðŸ” é¦¬åã§æ¤œç´¢", key="horse_search")

        if search_term:
            if "horse_name" in df.columns:
                filtered_df = df[df["horse_name"].str.contains(search_term, case=False, na=False)]
                st.info(f"ðŸ“Š æ¤œç´¢çµæžœ: {len(filtered_df):,}é ­")
            else:
                filtered_df = df
        else:
            filtered_df = df

        # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        st.markdown("#### ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€æ–°100ä»¶ï¼‰")

        display_cols = [
            "horse_id", "horse_name", "sex", "birth_date",
            "breeder", "trainer_name", "owner_name"
        ]

        available_cols = [col for col in display_cols if col in filtered_df.columns]

        st.dataframe(
            filtered_df[available_cols].head(100),
            use_container_width=True,
            hide_index=True
        )

        # çµ±è¨ˆæƒ…å ±
        if "sex" in df.columns:
            st.markdown("#### æ€§åˆ¥åˆ†å¸ƒ")
            sex_counts = df["sex"].value_counts()
            col1, col2, col3 = st.columns(3)

            for i, (sex, count) in enumerate(sex_counts.items()):
                with [col1, col2, col3][i % 3]:
                    st.metric(sex, f"{count:,}é ­")

    except Exception as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")


def render_pedigrees_explorer():
    """è¡€çµ±ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ©ãƒ¼"""

    st.markdown("### ðŸ§¬ è¡€çµ±ãƒ‡ãƒ¼ã‚¿")

    pedigrees_parquet = project_root / "keibaai" / "data" / "parsed" / "parquet" / "pedigrees" / "pedigrees.parquet"

    if not pedigrees_parquet.exists():
        st.warning("âš ï¸ è¡€çµ±ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    try:
        df = pd.read_parquet(pedigrees_parquet)

        st.success(f"âœ… {len(df):,}ä»¶ã®è¡€çµ±ãƒ‡ãƒ¼ã‚¿ï¼ˆ5ä¸–ä»£ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")

        # ä¸–ä»£åˆ¥ãƒ•ã‚£ãƒ«ã‚¿
        if "generation" in df.columns:
            generation = st.selectbox(
                "ä¸–ä»£",
                options=sorted(df["generation"].unique()),
                key="pedigree_generation_filter"
            )

            filtered_df = df[df["generation"] == generation]

            st.info(f"ðŸ“Š ç¬¬{generation}ä¸–ä»£: {len(filtered_df):,}ä»¶")

            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.markdown("#### ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€æ–°100ä»¶ï¼‰")

            display_cols = [
                "horse_id", "generation", "ancestor_id", "ancestor_name",
                "coat_color", "birth_year"
            ]

            available_cols = [col for col in display_cols if col in filtered_df.columns]

            st.dataframe(
                filtered_df[available_cols].head(100),
                use_container_width=True,
                hide_index=True
            )

    except Exception as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")


def render_shutuba_explorer():
    """å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ©ãƒ¼"""

    st.markdown("### ðŸ“‹ å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿")

    shutuba_parquet = project_root / "keibaai" / "data" / "parsed" / "parquet" / "shutuba" / "shutuba.parquet"

    if not shutuba_parquet.exists():
        st.warning("âš ï¸ å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    try:
        df = pd.read_parquet(shutuba_parquet)

        st.success(f"âœ… {len(df):,}ä»¶ã®å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")

        # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        st.markdown("#### ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€æ–°100ä»¶ï¼‰")

        display_cols = [
            "race_id", "bracket_number", "horse_number", "horse_id", "horse_name",
            "sex_age", "jockey_id", "jockey_name", "basis_weight", "morning_odds"
        ]

        available_cols = [col for col in display_cols if col in df.columns]

        st.dataframe(
            df[available_cols].head(100),
            use_container_width=True,
            hide_index=True
        )

    except Exception as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")


def render_statistics():
    """çµ±è¨ˆæƒ…å ±"""

    st.markdown("### ðŸ“Š ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆæƒ…å ±")

    stats = {}

    # ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
    races_parquet = project_root / "keibaai" / "data" / "parsed" / "parquet" / "races" / "races.parquet"
    if races_parquet.exists():
        try:
            df = pd.read_parquet(races_parquet)
            stats["races"] = {
                "ç·ãƒ¬ãƒ¼ã‚¹æ•°": len(df),
                "ã‚«ãƒ©ãƒ æ•°": len(df.columns),
                "ãƒ‡ãƒ¼ã‚¿æœŸé–“": f"{df['race_date'].min()} ï½ž {df['race_date'].max()}" if "race_date" in df.columns else "N/A",
                "ç«¶é¦¬å ´æ•°": df["venue"].nunique() if "venue" in df.columns else "N/A",
            }
        except:
            pass

    # é¦¬ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
    horses_parquet = project_root / "keibaai" / "data" / "parsed" / "parquet" / "horses" / "horses.parquet"
    if horses_parquet.exists():
        try:
            df = pd.read_parquet(horses_parquet)
            stats["horses"] = {
                "ç·é¦¬æ•°": len(df),
                "ã‚«ãƒ©ãƒ æ•°": len(df.columns),
            }
        except:
            pass

    # è¡€çµ±ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
    pedigrees_parquet = project_root / "keibaai" / "data" / "parsed" / "parquet" / "pedigrees" / "pedigrees.parquet"
    if pedigrees_parquet.exists():
        try:
            df = pd.read_parquet(pedigrees_parquet)
            stats["pedigrees"] = {
                "ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°": len(df),
                "ä¸–ä»£æ•°": df["generation"].nunique() if "generation" in df.columns else "N/A",
            }
        except:
            pass

    # è¡¨ç¤º
    if not stats:
        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    for data_type, data_stats in stats.items():
        st.markdown(f"#### {data_type.capitalize()}ãƒ‡ãƒ¼ã‚¿")
        cols = st.columns(len(data_stats))
        for i, (key, value) in enumerate(data_stats.items()):
            with cols[i]:
                st.metric(key, value)

        st.markdown("---")
