#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®æ­£ç‰ˆãƒ‘ãƒ¼ã‚µãƒ¼ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ å‹•ä½œç¢ºèªç”¨ãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (v3)

(v3 å¤‰æ›´ãªã—)
- data_utils.py ã® v3 ä¿®æ­£ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ãŸã‚ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import shutil
import logging
import sys
import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq
from datetime import date, datetime, timezone, timedelta
from pathlib import Path
import sqlite3
import traceback

# --- ãƒ­ã‚®ãƒ³ã‚°è¨­å®š ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] (%(filename)s:%(lineno)d) - %(message)s',
    stream=sys.stdout
)

# --- (v3) ãƒ€ãƒŸãƒ¼ 'modules' ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å¼·åˆ¶ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— ---
PROJECT_ROOT = Path.cwd()
DUMMY_MODULES_DIR = PROJECT_ROOT / 'modules'

def pre_cleanup():
    """
    ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å‰ã«ã€CWD (ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ) ã«å­˜åœ¨ã™ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹
    v1 ãŒä½œæˆã—ãŸãƒ€ãƒŸãƒ¼ 'modules' ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤ã™ã‚‹ã€‚
    """
    try:
        if DUMMY_MODULES_DIR.is_dir():
            logging.warning(f"ç«¶åˆã®å¯èƒ½æ€§ãŒã‚ã‚‹ãƒ€ãƒŸãƒ¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤ã—ã¾ã™: {DUMMY_MODULES_DIR}")
            shutil.rmtree(DUMMY_MODULES_DIR)
            logging.info("ãƒ€ãƒŸãƒ¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‰Šé™¤å®Œäº†ã€‚")
    except Exception as e:
        logging.error(f"ãƒ€ãƒŸãƒ¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã«å¤±æ•—: {e}")
        logging.error("ãƒ†ã‚¹ãƒˆã‚’ç¶šè¡Œã—ã¾ã™ãŒã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå¤±æ•—ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

# --- ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ ---
# 1. (v3) ç«¶åˆã™ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ãƒ€ãƒŸãƒ¼ã‚’å…ˆã«å‰Šé™¤
pre_cleanup()

# 2. (v2) 'keibaai/src' ã‚’ sys.path ã«è¿½åŠ 
SRC_DIR = PROJECT_ROOT / 'keibaai' / 'src'
if not SRC_DIR.exists():
    logging.error(f"ã‚¨ãƒ©ãƒ¼: `keibaai/src` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    logging.error(f"æƒ³å®šãƒ‘ã‚¹: {SRC_DIR}")
    logging.error("ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ (Keiba_AI_v2) ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    sys.exit(1)

sys.path.insert(0, str(SRC_DIR))
logging.info(f"`keibaai/src` ã‚’ sys.path ã«è¿½åŠ ã—ã¾ã—ãŸ: {SRC_DIR}")

# 3. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    logging.info("ä¿®æ­£ç‰ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­...")
    
    # keibaai/src/modules/parsers/horse_info_parser.py
    from modules.parsers.horse_info_parser import parse_horse_profile, parse_horse_performance
    
    # keibaai/src/modules/parsers/results_parser.py
    from modules.parsers.results_parser import parse_results_html
    
    # keibaai/src/utils/data_utils.py
    from utils.data_utils import load_parquet_data_by_date
    
    # keibaai/src/pipeline_core.py
    from pipeline_core import parse_with_error_handling, get_db_connection

    # keibaai/src/modules/parsers/common_utils.py (å®Ÿãƒ•ã‚¡ã‚¤ãƒ«)
    import modules.parsers.common_utils

    logging.info("ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸã€‚")

except ImportError as e:
    logging.error(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    logging.error(traceback.format_exc())
    logging.error("`keibaai/src` ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆãŒæ­£ã—ã„ã‹ã€")
    logging.error("`__init__.py` ãƒ•ã‚¡ã‚¤ãƒ«ãŒå„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (modules, modules/parsers, utils) ã«å­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    sys.exit(1)
except Exception as e:
    logging.error(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    logging.error(traceback.format_exc())
    sys.exit(1)


# --- ãƒ†ã‚¹ãƒˆç”¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ---
# (ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆç›´ä¸‹ã« debug_workspace ã‚’ä½œæˆ)
WORKSPACE_DIR = PROJECT_ROOT / "debug_workspace"
HTML_DIR = WORKSPACE_DIR / "html"
PARQUET_DIR = WORKSPACE_DIR / "parquet"
DB_PATH = WORKSPACE_DIR / "debug_db.sqlite3"

# --- ãƒ€ãƒŸãƒ¼HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
# 1. é¦¬ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ« (æˆåŠŸã‚±ãƒ¼ã‚¹)
horse_ok_html = """
<html><body>
    <div class="horse_title"><h1>ãƒ†ã‚¹ãƒˆãƒ›ãƒ¼ã‚¹</h1></div>
    <table class="db_prof_table">
        <tr><th>ç”Ÿå¹´æœˆæ—¥</th><td>2020å¹´3æœˆ15æ—¥</td></tr>
        <tr><th>æ€§åˆ¥</th><td>ç‰¡</td></tr>
    </table>
    <table class="blood_table">
        </table>
</body></html>
"""

# 2. é¦¬ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ« (å¤±æ•—ã‚±ãƒ¼ã‚¹: db_prof_table ãŒãªã„)
horse_ng_html = """
<html><body>
    <div class="horse_title"><h1>ãƒ‡ãƒ¼ã‚¿æ¬ æãƒ›ãƒ¼ã‚¹</h1></div>
    </body></html>
"""

# 3. ãƒ¬ãƒ¼ã‚¹çµæœ (æˆåŠŸã‚±ãƒ¼ã‚¹)
results_ok_html = """
<html><body>
    <p class="smalltxt">2023å¹´05æœˆ14æ—¥ 2å›æ±äº¬8æ—¥ç›® 11R</p>
    <table class="race_table_01">
        <tbody>
            <tr>
                <td>1</td><td>1</td><td>1</td>
                <td><a href="/horse/2020100001">ã‚¤ã‚¯ã‚¤ãƒãƒƒã‚¯ã‚¹</a></td>
                <td>ç‰¡3</td><td>57.0</td>
                <td><a href="/jockey/00001">ãƒ«ãƒ¡ãƒ¼ãƒ«</a></td>
                <td>1:58.5</td><td>-</td><td></td>
                <td>2-2-2</td><td>34.5</td>
                <td>1.5</td><td>1</td><td>480(0)</td>
                <td><a href="/trainer/0001">æœ¨æ‘</a></td>
                <td>ã‚·ãƒ«ã‚¯ï¼²</td><td>10000.0</td>
            </tr>
            <tr>
                <td>2</td><td>2</td><td>2</td>
                <td><a href="/horse/2020100002">ãƒ‰ã‚¦ãƒ‡ãƒ¥ãƒ¼ã‚¹</a></td>
                <td>ç‰¡3</td><td>57.0</td>
                <td><a href="/jockey/00002">æ­¦è±Š</a></td>
                <td>1:58.6</td><td>1/2</td><td></td>
                <td>3-3-3</td><td>34.6</td>
                <td>3.0</td><td>2</td><td>500(+2)</td>
                <td><a href="/trainer/0002">å‹é“</a></td>
                <td>ã‚­ãƒ¼ãƒ•ã‚¡ãƒ¼ã‚º</td><td>4000.0</td>
            </tr>
        </tbody>
    </table>
</body></html>
"""

def setup_workspace():
    """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ãƒ€ãƒŸãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    logging.info(f"ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã‚’ä½œæˆä¸­: {WORKSPACE_DIR}")
    if WORKSPACE_DIR.exists():
        shutil.rmtree(WORKSPACE_DIR)
    HTML_DIR.mkdir(parents=True, exist_ok=True)
    PARQUET_DIR.mkdir(parents=True, exist_ok=True)

    # ãƒ€ãƒŸãƒ¼HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ (euc_jp ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰)
    try:
        (HTML_DIR / "horse_ok.html").write_bytes(horse_ok_html.encode('euc_jp'))
        (HTML_DIR / "horse_ng.html").write_bytes(horse_ng_html.encode('euc_jp'))
        (HTML_DIR / "results_ok.html").write_bytes(results_ok_html.encode('euc_jp'))
    except Exception as e:
        logging.error(f"ãƒ€ãƒŸãƒ¼HTMLã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰/æ›¸ãè¾¼ã¿å¤±æ•—: {e}")
        logging.warning("ãƒ†ã‚¹ãƒˆã‚’ç¶šè¡Œã—ã¾ã™ãŒã€ãƒ‘ãƒ¼ã‚¹ãŒå¤±æ•—ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        (HTML_DIR / "horse_ok.html").write_text(horse_ok_html, encoding='utf-8')
        (HTML_DIR / "horse_ng.html").write_text(horse_ng_html, encoding='utf-8')
        (HTML_DIR / "results_ok.html").write_text(results_ok_html, encoding='utf-8')


    # ãƒ€ãƒŸãƒ¼Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ (data_utils.py ãƒ†ã‚¹ãƒˆç”¨)
    logging.info(f"ãƒ€ãƒŸãƒ¼Parquetã‚’ä½œæˆä¸­: {PARQUET_DIR}")
    df_parquet = pd.DataFrame({
        'race_id': [f'20230101{i:02d}' for i in range(1, 6)],
        'race_date': [
            date(2023, 10, 1),
            date(2023, 10, 1),
            date(2023, 11, 5),
            date(2023, 12, 20),
            date(2023, 12, 25),
        ],
        'value': [100, 200, 300, 400, 500]
    })
    
    # Hiveãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã®ãŸã‚ã« 'year' ã¨ 'month' ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
    df_parquet['year'] = pd.to_datetime(df_parquet['race_date']).dt.year
    df_parquet['month'] = pd.to_datetime(df_parquet['race_date']).dt.month

    table = pa.Table.from_pandas(df_parquet)
    
    # Hiveå½¢å¼ã§ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³åˆ†å‰²ã—ã¦æ›¸ãè¾¼ã¿
    pq.write_to_dataset(
        table,
        root_path=PARQUET_DIR,
        partition_cols=['year', 'month']
    )
    
    logging.info("ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã®æº–å‚™å®Œäº†ã€‚")

def cleanup_workspace():
    """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
    logging.info(f"ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­: {WORKSPACE_DIR}")
    if WORKSPACE_DIR.exists():
        shutil.rmtree(WORKSPACE_DIR)
    
    # (v3) v1 ãŒ CWD ã«ä½œæˆã—ãŸãƒ€ãƒŸãƒ¼ 'modules' ã‚‚ï¼ˆæ®‹ã£ã¦ã„ã‚Œã°ï¼‰å‰Šé™¤
    if DUMMY_MODULES_DIR.exists():
        logging.warning(f"CWDã®ãƒ€ãƒŸãƒ¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {DUMMY_MODULES_DIR}")
        shutil.rmtree(DUMMY_MODULES_DIR)

    logging.info("ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†ã€‚")

# === ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ ===

def test_horse_info_parser():
    """ 1. horse_info_parser.py ã®ãƒ†ã‚¹ãƒˆ """
    logging.info("--- 1. test_horse_info_parser é–‹å§‹ ---")
    test_passed = True
    
    # (A) æˆåŠŸã‚±ãƒ¼ã‚¹
    try:
        ok_path = str(HTML_DIR / "horse_ok.html")
        profile = parse_horse_profile(ok_path, "2020100001")
        birth_date_val = profile.get('birth_date')
        
        if isinstance(birth_date_val, date):
            logging.info(f" [æˆåŠŸ] (A) æ­£å¸¸ãªHTMLã®ãƒ‘ãƒ¼ã‚¹ã«æˆåŠŸã€‚birth_date ã®å‹: {type(birth_date_val)}")
            if birth_date_val != date(2020, 3, 15):
                logging.error(f" [å¤±æ•—] (A) æ—¥ä»˜ã®å€¤ãŒä¸æ­£ã§ã™ã€‚æœŸå¾…å€¤: {date(2020, 3, 15)}, å®Ÿéš›: {birth_date_val}")
                test_passed = False
        else:
            logging.error(f" [å¤±æ•—] (A) birth_date ãŒ date ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å‹: {type(birth_date_val)}")
            test_passed = False
            
    except Exception as e:
        logging.error(f" [å¤±æ•—] (A) æ­£å¸¸ãªHTMLã®ãƒ‘ãƒ¼ã‚¹ã§äºˆæœŸã›ã¬ä¾‹å¤–ãŒç™ºç”Ÿ: {e}\n{traceback.format_exc()}")
        test_passed = False

    # (B) å¤±æ•—ã‚±ãƒ¼ã‚¹ (ã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³ã®é˜²æ­¢)
    conn = None
    try:
        conn = get_db_connection(str(DB_PATH))
        conn.execute("""
            CREATE TABLE IF NOT EXISTS parse_failures (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                parser_name TEXT,
                source_file TEXT,
                error_type TEXT,
                error_message TEXT,
                stack_trace TEXT,
                failed_ts TEXT
            )
        """)
        
        ng_path = str(HTML_DIR / "horse_ng.html")
        
        result = parse_with_error_handling(
            file_path=ng_path,
            parser_name="test_horse_profile_ng",
            parse_func=lambda p: parse_horse_profile(p, "2020100002"),
            db_conn=conn
        )
        
        if result is not None:
            logging.error(f" [å¤±æ•—] (B) ã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³ãƒ†ã‚¹ãƒˆå¤±æ•—ã€‚ãƒ‘ãƒ¼ã‚µãƒ¼ãŒ None ã‚’è¿”ã—ã¾ã›ã‚“ã§ã—ãŸã€‚ result: {result}")
            test_passed = False
        else:
            logging.info(" [æˆåŠŸ] (B) ã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³ãƒ†ã‚¹ãƒˆ: ãƒ‘ãƒ¼ã‚µãƒ¼ãŒ None ã‚’è¿”ã—ã¾ã—ãŸã€‚")
            
        cursor = conn.cursor()
        cursor.execute("SELECT error_type, error_message FROM parse_failures WHERE source_file = ?", (ng_path,))
        failure = cursor.fetchone()
        
        if failure and failure[0] == 'ValueError':
            logging.info(f" [æˆåŠŸ] (B) DBã« 'ValueError' ãŒæ­£ã—ãè¨˜éŒ²ã•ã‚Œã¾ã—ãŸã€‚")
            logging.info(f"     ã‚¨ãƒ©ãƒ¼å†…å®¹: {failure[1][:80]}...")
        elif failure:
            logging.error(f" [å¤±æ•—] (B) DBã«è¨˜éŒ²ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼å‹ãŒä¸æ­£ã§ã™ã€‚æœŸå¾…å€¤: 'ValueError', å®Ÿéš›: '{failure[0]}'")
            test_passed = False
        else:
            logging.error(f" [å¤±æ•—] (B) DBã«ã‚¨ãƒ©ãƒ¼ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            test_passed = False

    except Exception as e:
        logging.error(f" [å¤±æ•—] (B) å¤±æ•—ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆä¸­ã«äºˆæœŸã›ã¬ä¾‹å¤–ãŒç™ºç”Ÿ: {e}\n{traceback.format_exc()}")
        test_passed = False
    finally:
        if conn:
            conn.close()
            
    logging.info(f"--- 1. test_horse_info_parser çµ‚äº† ({'æˆåŠŸ' if test_passed else 'å¤±æ•—'}) ---")
    return test_passed


def test_results_parser():
    """ 2. results_parser.py ã®ãƒ†ã‚¹ãƒˆ """
    logging.info("--- 2. test_results_parser é–‹å§‹ ---")
    test_passed = True
    
    try:
        ok_path = str(HTML_DIR / "results_ok.html")
        df = parse_results_html(ok_path, "202305020811")
        
        if df.empty or 'race_date' not in df.columns:
            logging.error(f" [å¤±æ•—] ãƒ‘ãƒ¼ã‚¹çµæœãŒç©ºã‹ã€'race_date' ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
            test_passed = False
            return False

        if df['race_date'].dtype != 'object':
            logging.warning(f" [è­¦å‘Š] race_date ã‚«ãƒ©ãƒ ã® dtype ãŒ 'object' ã§ã¯ã‚ã‚Šã¾ã›ã‚“ (å®Ÿéš›: {df['race_date'].dtype})ã€‚")

        first_date_val = df['race_date'].iloc[0]
        if isinstance(first_date_val, date):
            logging.info(f" [æˆåŠŸ] 'race_date' ã‚«ãƒ©ãƒ ã®è¦ç´ ã¯ date ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã™ã€‚å‹: {type(first_date_val)}")
            if first_date_val != date(2023, 5, 14):
                logging.error(f" [å¤±æ•—] æ—¥ä»˜ã®å€¤ãŒä¸æ­£ã§ã™ã€‚æœŸå¾…å€¤: {date(2023, 5, 14)}, å®Ÿéš›: {first_date_val}")
                test_passed = False
        else:
            logging.error(f" [å¤±æ•—] 'race_date' ã‚«ãƒ©ãƒ ã®è¦ç´ ãŒ date ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å‹: {type(first_date_val)}")
            test_passed = False
            
    except Exception as e:
        logging.error(f" [å¤±æ•—] results_parser ã®ãƒ†ã‚¹ãƒˆä¸­ã«äºˆæœŸã›ã¬ä¾‹å¤–ãŒç™ºç”Ÿ: {e}\n{traceback.format_exc()}")
        test_passed = False

    logging.info(f"--- 2. test_results_parser çµ‚äº† ({'æˆåŠŸ' if test_passed else 'å¤±æ•—'}) ---")
    return test_passed


def test_data_utils_loader():
    """ 3. data_utils.py ã®ãƒ†ã‚¹ãƒˆ """
    logging.info("--- 3. test_data_utils_loader é–‹å§‹ ---")
    test_passed = True
    
    test_cases = [
        # (ãƒ†ã‚¹ãƒˆå, start_dt, end_dt, æœŸå¾…ã•ã‚Œã‚‹è¡Œæ•°)
        ("å…¨æœŸé–“ (None)", None, None, 5),
        ("2023-11-01 ä»¥é™", datetime(2023, 11, 1), None, 3),
        ("2023-11-30 ä»¥å‰", None, datetime(2023, 11, 30), 3),
        ("2023-10-01 ã®ã¿", datetime(2023, 10, 1), datetime(2023, 10, 1), 2),
        ("2023-11-01 ï½ 2023-12-20", datetime(2023, 11, 1), datetime(2023, 12, 20), 2),
        ("ç¯„å›²å¤– (æœªæ¥)", datetime(2024, 1, 1), None, 0),
        ("ç¯„å›²å¤– (éå»)", None, datetime(2023, 1, 1), 0),
    ]

    for name, start_dt, end_dt, expected_rows in test_cases:
        try:
            df = load_parquet_data_by_date(
                base_dir=PARQUET_DIR,
                start_dt=start_dt,
                end_dt=end_dt,
                date_col='race_date'
            )
            
            if len(df) == expected_rows:
                logging.info(f" [æˆåŠŸ] ({name}) æœŸå¾…é€šã‚Šã®è¡Œæ•°ã‚’å–å¾—: {len(df)}")
            else:
                logging.error(f" [å¤±æ•—] ({name}) è¡Œæ•°ãŒç•°ãªã‚Šã¾ã™ã€‚æœŸå¾…å€¤: {expected_rows}, å®Ÿéš›: {len(df)}")
                test_passed = False
        except Exception as e:
            logging.error(f" [å¤±æ•—] ({name}) data_utils ã®ãƒ†ã‚¹ãƒˆä¸­ã«äºˆæœŸã›ã¬ä¾‹å¤–ãŒç™ºç”Ÿ: {e}\n{traceback.format_exc()}")
            test_passed = False

    logging.info(f"--- 3. test_data_utils_loader çµ‚äº† ({'æˆåŠŸ' if test_passed else 'å¤±æ•—'}) ---")
    return test_passed


def main():
    try:
        setup_workspace()
        
        results = []
        results.append(test_horse_info_parser())
        results.append(test_results_parser())
        results.append(test_data_utils_loader())
        
        logging.info("="*50)
        if all(results):
            logging.info("ğŸ‰ å…¨ã¦ã®ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸã€‚")
        else:
            logging.error(f"ğŸ”¥ ä¸€éƒ¨ã®ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ (æˆåŠŸ: {sum(results)}/{len(results)})")
            
    except Exception as e:
        logging.error(f"ãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œä¸­ã«è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        logging.error(traceback.format_exc())
        
    finally:
        cleanup_workspace()

if __name__ == "__main__":
    main()