import pandas as pd
from pathlib import Path
import logging
import sys

# --- æº–å‚™ ---
try:
    import pyarrow
except ImportError:
    print("=" * 70, file=sys.stderr)
    print(" ã‚¨ãƒ©ãƒ¼: 'pyarrow' ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", file=sys.stderr)
    print(" ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ pip install pyarrow ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚", file=sys.stderr)
    print("=" * 70, file=sys.stderr)
    sys.exit(1)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- è¨­å®š ---
BASE_DIR = Path.cwd() 
PARSED_DIR = BASE_DIR / "keibaai" / "data" / "parsed" / "parquet"

# â˜…â˜…â˜… ä¿®æ­£ç‚¹ â˜…â˜…â˜…
# pipeline_core.py ã®ä»•æ§˜ã«åŸºã¥ãã€å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
DATASETS_TO_CHECK_MAP = {
    # 'key' : 'path_relative_to_parsed_dir'
    "race": Path("races/races.parquet"),
    "horse_info": Path("horses/horses.parquet"),
    "pedigree": Path("pedigrees/pedigrees.parquet"),
    "shutuba": Path("shutuba") # shutuba ã®ã¿ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³åˆ†å‰²ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
}
# â˜…â˜…â˜… ä¿®æ­£ã“ã“ã¾ã§ â˜…â˜…â˜…


logger.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {BASE_DIR}")
logger.info(f"ç¢ºèªå¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {PARSED_DIR}")
print("-" * 70)

all_success = True
found_any_data = False

# --- ãƒ‡ãƒãƒƒã‚°å®Ÿè¡Œ ---
for dataset_name, relative_path in DATASETS_TO_CHECK_MAP.items():
    logger.info(f"ã€{dataset_name}ã€‘ã®ç¢ºèªã‚’é–‹å§‹...")
    
    full_path = PARSED_DIR / relative_path
    
    # 1. ãƒ‘ã‚¹(ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª)ã®å­˜åœ¨ç¢ºèª
    if not full_path.exists():
        logger.warning(f"  [çµæœ] âŒ FAILED: ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {full_path}")
        all_success = False
        print("-" * 70)
        continue

    # 3. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å†…å®¹ç¢ºèª
    try:
        df = pd.DataFrame()
        if full_path.is_dir():
            # 'shutuba' ã®ã‚ˆã†ãªãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³åˆ†å‰²ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å ´åˆ
            parquet_files = list(full_path.glob("**/*.parquet"))
            if not parquet_files:
                 logger.warning(f"  [çµæœ] âŒ FAILED: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã« .parquet ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {full_path}")
                 all_success = False
                 print("-" * 70)
                 continue
            
            logger.info(f"  [æƒ…å ±] {len(parquet_files)} å€‹ã® Parquet ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ï¼‰ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚")
            df = pd.read_parquet(full_path)
        else:
            # 'race', 'horse_info', 'pedigree' ã®ã‚ˆã†ãªå˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
            logger.info(f"  [æƒ…å ±] å˜ä¸€ã® Parquet ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹ã—ã¾ã—ãŸ: {full_path}")
            df = pd.read_parquet(full_path)
        
        # --- èª­ã¿è¾¼ã¿å¾Œã®å…±é€šãƒã‚§ãƒƒã‚¯ ---
        if df.empty:
            logger.warning(f"  [çµæœ] âš ï¸ WARNING: ãƒ‡ãƒ¼ã‚¿ã¯èª­ã¿è¾¼ã‚ã¾ã—ãŸãŒã€ä¸­èº«ãŒç©ºã§ã™ (0è¡Œ)ã€‚")
            logger.warning("          (æ³¨: 1000ä»¶ã®ãƒ‡ãƒãƒƒã‚°å®Ÿè¡Œã§ã¯ã€å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œãªã„å ´åˆã‚‚ã‚ã‚Šã¾ã™)")
        else:
            logger.info(f"  [çµæœ] âœ… SUCCESS: æ­£å¸¸ã«èª­ã¿è¾¼ã¿å®Œäº†ã€‚")
            logger.info(f"  [æƒ…å ±] ç·è¡Œæ•°: {len(df)}")
            logger.info(f"  [æƒ…å ±] ã‚«ãƒ©ãƒ æ•°: {len(df.columns)}")
            print("--- å…ˆé ­5è¡Œ (head) ---")
            pd.set_option('display.max_columns', None) # å…¨ã¦ã®ã‚«ãƒ©ãƒ ã‚’è¡¨ç¤º
            print(df.head())
            print("." * 20)
            found_any_data = True

    except Exception as e:
        logger.error(f"  [çµæœ] âŒ FAILED: Parquet ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        logger.error(f"  ãƒ‘ã‚¹: {full_path}")
        logger.error(f"  ã‚¨ãƒ©ãƒ¼å†…å®¹: {e}")
        all_success = False

    print("-" * 70)

# --- ç·åˆçµæœ ---
if all_success and found_any_data:
    logger.info("ğŸ‰ ç·åˆçµæœ: ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã‚ã€ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚")
elif all_success and not found_any_data:
    logger.warning("ğŸ¤” ç·åˆçµæœ: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯æ­£å¸¸ã«å‹•ä½œã—ã¾ã—ãŸãŒã€å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒç©ºã§ã—ãŸã€‚")
    logger.warning("          debug_run_parsing_pipeline_local_1000.py ã®å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«(1000ä»¶)ã«å‡¦ç†å¯¾è±¡ãŒå«ã¾ã‚Œã¦ã„ãªã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
else:
    logger.error("ğŸ”¥ ç·åˆçµæœ: ã„ãã¤ã‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç¢ºèªã«å¤±æ•—ã—ã¾ã—ãŸã€‚ä¸Šè¨˜ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")