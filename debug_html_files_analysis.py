#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ã®åŸå› ç‰¹å®šã®ãŸã‚ã€ä»¥ä¸‹ã‚’èª¿æŸ»ï¼š
1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®çµ±è¨ˆï¼ˆå¹´åˆ¥ã€ç¨®é¡åˆ¥ï¼‰
2. ç©ºãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ç•°å¸¸ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œå‡º
3. 2025å¹´ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°èª¿æŸ»
4. ã‚µãƒ³ãƒ—ãƒ«HTMLã®å†…å®¹ç¢ºèª
"""

import sys
from pathlib import Path
from collections import defaultdict, Counter
from datetime import datetime
import json

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
project_root = Path(__file__).resolve().parent
sys.path.append(str(project_root))


class HTMLFileAnalyzer:
    """HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.html_dir = data_dir / "raw" / "html"
        self.stats = {
            'race': defaultdict(list),
            'shutuba': defaultdict(list),
            'horse': defaultdict(list),
            'ped': defaultdict(list),
        }
        self.suspicious_files = []
        self.empty_files = []

    def analyze_all(self):
        """å…¨HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ"""
        print("ğŸ” HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°åˆ†æã‚’é–‹å§‹\n")
        print("=" * 80)

        # å„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åˆ†æ
        for file_type in ['race', 'shutuba', 'horse', 'ped']:
            dir_path = self.html_dir / file_type
            if dir_path.exists():
                print(f"\nğŸ“ {file_type}ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åˆ†æä¸­...")
                self._analyze_directory(dir_path, file_type)

        # çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ
        self._print_statistics()
        self._print_suspicious_files()
        self._print_sample_contents()

    def _analyze_directory(self, dir_path: Path, file_type: str):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ"""
        files = list(dir_path.glob("*.bin"))
        print(f"   ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(files):,}")

        for file_path in files:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå–å¾—
            size = file_path.stat().st_size

            # race_idã¾ãŸã¯horse_idã‚’æŠ½å‡º
            file_id = self._extract_id(file_path.stem)
            year = self._extract_year(file_id)

            # çµ±è¨ˆã«è¿½åŠ 
            self.stats[file_type][year].append({
                'file_path': str(file_path),
                'file_id': file_id,
                'size': size,
                'name': file_path.name
            })

            # ç©ºãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
            if size == 0:
                self.empty_files.append({
                    'type': file_type,
                    'path': str(file_path),
                    'id': file_id,
                    'size': 0
                })
            # ç•°å¸¸ã«å°ã•ã„ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ1KBæœªæº€ï¼‰
            elif size < 1024:
                self.suspicious_files.append({
                    'type': file_type,
                    'path': str(file_path),
                    'id': file_id,
                    'size': size,
                    'reason': f'ç•°å¸¸ã«å°ã•ã„ ({size} bytes)'
                })

    def _extract_id(self, filename: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰IDéƒ¨åˆ†ã‚’æŠ½å‡º"""
        # race, shutuba: 202310010201.bin
        # horse: 2009100502_profile.bin, 2009100502_perf.bin
        # ped: 2009100502.bin

        # _ãŒã‚ã‚‹å ´åˆã¯åˆ†å‰²
        if '_' in filename:
            return filename.split('_')[0]
        return filename

    def _extract_year(self, file_id: str) -> int:
        """IDã‹ã‚‰å¹´ã‚’æŠ½å‡º"""
        # æœ€åˆã®4æ¡ã‚’å¹´ã¨ã™ã‚‹
        if len(file_id) >= 4:
            try:
                return int(file_id[:4])
            except ValueError:
                return 0
        return 0

    def _print_statistics(self):
        """çµ±è¨ˆæƒ…å ±ã‚’å‡ºåŠ›"""
        print("\n" + "=" * 80)
        print("ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆï¼ˆå¹´åˆ¥ï¼‰")
        print("=" * 80)

        for file_type in ['race', 'shutuba', 'horse', 'ped']:
            if not self.stats[file_type]:
                continue

            print(f"\nâ–  {file_type.upper()} ãƒ•ã‚¡ã‚¤ãƒ«:")
            print(f"{'å¹´':<8} {'ãƒ•ã‚¡ã‚¤ãƒ«æ•°':>10} {'å¹³å‡ã‚µã‚¤ã‚º':>15} {'æœ€å°':>12} {'æœ€å¤§':>12}")
            print("-" * 80)

            years = sorted(self.stats[file_type].keys())
            total_files = 0
            total_size = 0

            for year in years:
                files = self.stats[file_type][year]
                count = len(files)
                sizes = [f['size'] for f in files]
                avg_size = sum(sizes) / len(sizes) if sizes else 0
                min_size = min(sizes) if sizes else 0
                max_size = max(sizes) if sizes else 0

                total_files += count
                total_size += sum(sizes)

                print(f"{year:<8} {count:>10,} {self._format_size(avg_size):>15} "
                      f"{self._format_size(min_size):>12} {self._format_size(max_size):>12}")

            print("-" * 80)
            print(f"{'åˆè¨ˆ':<8} {total_files:>10,} {self._format_size(total_size/total_files if total_files else 0):>15} "
                  f"{'':>12} {self._format_size(total_size):>12}")

    def _print_suspicious_files(self):
        """ç–‘ã‚ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›"""
        print("\n" + "=" * 80)
        print("âš ï¸  ç–‘ã‚ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«")
        print("=" * 80)

        # ç©ºãƒ•ã‚¡ã‚¤ãƒ«
        if self.empty_files:
            print(f"\nâ–  ç©ºãƒ•ã‚¡ã‚¤ãƒ«: {len(self.empty_files):,}ä»¶")
            print(f"{'ç¨®åˆ¥':<10} {'ãƒ•ã‚¡ã‚¤ãƒ«ID':<15} {'ãƒ‘ã‚¹'}")
            print("-" * 80)
            for file_info in self.empty_files[:20]:  # æœ€åˆã®20ä»¶ã®ã¿
                print(f"{file_info['type']:<10} {file_info['id']:<15} {Path(file_info['path']).name}")

            if len(self.empty_files) > 20:
                print(f"... ä»– {len(self.empty_files) - 20:,}ä»¶")
        else:
            print("\nâœ… ç©ºãƒ•ã‚¡ã‚¤ãƒ«ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

        # ç•°å¸¸ã«å°ã•ã„ãƒ•ã‚¡ã‚¤ãƒ«
        if self.suspicious_files:
            print(f"\nâ–  ç•°å¸¸ã«å°ã•ã„ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ<1KBï¼‰: {len(self.suspicious_files):,}ä»¶")
            print(f"{'ç¨®åˆ¥':<10} {'ãƒ•ã‚¡ã‚¤ãƒ«ID':<15} {'ã‚µã‚¤ã‚º':<12} {'ãƒ‘ã‚¹'}")
            print("-" * 80)
            for file_info in self.suspicious_files[:20]:  # æœ€åˆã®20ä»¶ã®ã¿
                print(f"{file_info['type']:<10} {file_info['id']:<15} "
                      f"{self._format_size(file_info['size']):<12} {Path(file_info['path']).name}")

            if len(self.suspicious_files) > 20:
                print(f"... ä»– {len(self.suspicious_files) - 20:,}ä»¶")
        else:
            print("\nâœ… ç•°å¸¸ã«å°ã•ã„ãƒ•ã‚¡ã‚¤ãƒ«ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    def _print_sample_contents(self):
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è¡¨ç¤º"""
        print("\n" + "=" * 80)
        print("ğŸ“„ ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ç¢ºèª")
        print("=" * 80)

        # 2025å¹´ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—
        samples_2025 = []
        for file_type in ['race', 'shutuba']:
            if 2025 in self.stats[file_type]:
                files = self.stats[file_type][2025]
                if files:
                    samples_2025.append((file_type, files[0]))

        # æ­£å¸¸ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆ2023å¹´ï¼‰
        samples_normal = []
        for file_type in ['race', 'shutuba']:
            if 2023 in self.stats[file_type]:
                files = self.stats[file_type][2023]
                # ã‚µã‚¤ã‚ºãŒå¤§ãã„ã‚‚ã®ï¼ˆæ­£å¸¸ã¨æ€ã‚ã‚Œã‚‹ï¼‰
                large_files = [f for f in files if f['size'] > 10000]
                if large_files:
                    samples_normal.append((file_type, large_files[0]))

        # 2025å¹´ã‚µãƒ³ãƒ—ãƒ«
        if samples_2025:
            print("\nâ–  2025å¹´ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰:")
            for file_type, file_info in samples_2025[:2]:
                self._print_file_content(file_info['file_path'], file_type, 500)

        # æ­£å¸¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒ³ãƒ—ãƒ«
        if samples_normal:
            print("\nâ–  æ­£å¸¸ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ2023å¹´ï¼‰ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰:")
            for file_type, file_info in samples_normal[:2]:
                self._print_file_content(file_info['file_path'], file_type, 500)

    def _print_file_content(self, file_path: str, file_type: str, max_chars: int = 500):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è¡¨ç¤º"""
        path = Path(file_path)
        print(f"\n  ğŸ“„ {file_type} - {path.name} ({self._format_size(path.stat().st_size)})")
        print("  " + "-" * 76)

        try:
            with open(path, 'rb') as f:
                content_bytes = f.read(max_chars * 2)  # ä½™è£•ã‚’æŒã£ã¦èª­ã‚€

            # EUC-JPã§ãƒ‡ã‚³ãƒ¼ãƒ‰è©¦è¡Œ
            try:
                content = content_bytes.decode('euc_jp', errors='replace')
            except:
                try:
                    content = content_bytes.decode('utf-8', errors='replace')
                except:
                    content = str(content_bytes[:max_chars])

            # æœ€åˆã®max_charsæ–‡å­—ã‚’è¡¨ç¤º
            content_preview = content[:max_chars]

            # æ”¹è¡Œã§åˆ†å‰²ã—ã¦æœ€åˆã®10è¡Œã®ã¿
            lines = content_preview.split('\n')[:10]
            for line in lines:
                print(f"  {line[:74]}")

            if len(content) > max_chars:
                print(f"  ... (ä»¥ä¸‹çœç•¥)")

        except Exception as e:
            print(f"  âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    def _format_size(self, size: float) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if size < 1024:
            return f"{size:.0f} B"
        elif size < 1024 * 1024:
            return f"{size/1024:.1f} KB"
        else:
            return f"{size/(1024*1024):.2f} MB"

    def save_report(self, output_path: Path):
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONã§ä¿å­˜"""
        report = {
            'metadata': {
                'analysis_datetime': datetime.now().isoformat(),
                'data_directory': str(self.data_dir),
            },
            'statistics': {},
            'empty_files': self.empty_files,
            'suspicious_files': self.suspicious_files,
        }

        # çµ±è¨ˆã‚’å¤‰æ›
        for file_type, years_data in self.stats.items():
            report['statistics'][file_type] = {}
            for year, files in years_data.items():
                report['statistics'][file_type][str(year)] = {
                    'count': len(files),
                    'total_size': sum(f['size'] for f in files),
                    'avg_size': sum(f['size'] for f in files) / len(files) if files else 0,
                    'files': [{'id': f['file_id'], 'size': f['size'], 'name': f['name']} for f in files[:100]]
                }

        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {output_path}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ” KeibaAI_v2 HTMLãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°åˆ†æ")
    print("=" * 80)

    data_dir = Path("keibaai/data")

    if not data_dir.exists():
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_dir}")
        return

    analyzer = HTMLFileAnalyzer(data_dir)
    analyzer.analyze_all()

    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_path = data_dir / "logs" / "analysis" / f"html_analysis_{timestamp}.json"
    analyzer.save_report(output_path)

    print("\n" + "=" * 80)
    print("âœ… åˆ†æå®Œäº†!")
    print("=" * 80)


if __name__ == "__main__":
    main()
