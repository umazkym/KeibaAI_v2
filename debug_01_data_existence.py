#!/usr/bin/env python3
"""
ãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ01: ãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ç¢ºèª
KeibaAI_v2ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ã‚’è©³ç´°ã«èª¿æŸ»ã—ã¾ã™
"""

import os
from pathlib import Path
from datetime import datetime

def check_directory_structure():
    """ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ç¢ºèª"""
    print("=" * 80)
    print("ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ç¢ºèª")
    print("=" * 80)

    base_paths = [
        "keibaai/data/raw/html/race",
        "keibaai/data/raw/html/shutuba",
        "keibaai/data/raw/html/horse",
        "keibaai/data/raw/html/ped",
        "keibaai/data/parsed/parquet/races",
        "keibaai/data/parsed/parquet/shutuba",
        "keibaai/data/parsed/parquet/horses",
        "keibaai/data/parsed/parquet/pedigrees",
        "keibaai/data/features/parquet",
        "keibaai/data/models",
        "keibaai/data/metadata",
    ]

    results = {}

    for path_str in base_paths:
        path = Path(path_str)
        exists = path.exists()

        if exists:
            # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            if path.is_dir():
                files = list(path.rglob("*"))
                file_count = len([f for f in files if f.is_file()])
                dir_count = len([f for f in files if f.is_dir()])

                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®åˆè¨ˆ
                total_size = sum(f.stat().st_size for f in files if f.is_file())
                size_mb = total_size / (1024 * 1024)

                results[path_str] = {
                    "exists": True,
                    "files": file_count,
                    "dirs": dir_count,
                    "size_mb": size_mb
                }
            else:
                results[path_str] = {
                    "exists": True,
                    "is_file": True
                }
        else:
            results[path_str] = {"exists": False}

    # çµæœã‚’è¡¨ç¤º
    print("\nğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåˆ¥ã®çŠ¶æ³:\n")
    for path_str, info in results.items():
        if info["exists"]:
            if "files" in info:
                status = f"âœ… å­˜åœ¨ | ãƒ•ã‚¡ã‚¤ãƒ«: {info['files']}ä»¶ | ã‚µã‚¤ã‚º: {info['size_mb']:.2f} MB"
            else:
                status = "âœ… å­˜åœ¨ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ï¼‰"
        else:
            status = "âŒ å­˜åœ¨ã—ãªã„"

        print(f"{path_str:50s} -> {status}")

    return results

def check_raw_html_samples():
    """raw HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç¢ºèª"""
    print("\n" + "=" * 80)
    print("RAW HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª")
    print("=" * 80)

    html_dirs = {
        "race": "keibaai/data/raw/html/race",
        "shutuba": "keibaai/data/raw/html/shutuba",
        "horse": "keibaai/data/raw/html/horse",
        "ped": "keibaai/data/raw/html/ped",
    }

    for name, dir_path in html_dirs.items():
        path = Path(dir_path)
        print(f"\nğŸ“„ {name} HTMLãƒ•ã‚¡ã‚¤ãƒ«:")

        if not path.exists():
            print(f"  âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {dir_path}")
            continue

        # æœ€åˆã®5ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
        files = sorted(path.glob("*"))[:5]

        if not files:
            print(f"  âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        else:
            for file in files:
                size_kb = file.stat().st_size / 1024
                mtime = datetime.fromtimestamp(file.stat().st_mtime)
                print(f"  - {file.name:40s} | {size_kb:>8.2f} KB | {mtime.strftime('%Y-%m-%d %H:%M:%S')}")

            total_files = len(list(path.glob("*")))
            print(f"  ğŸ“Š åˆè¨ˆ: {total_files}ä»¶")

def check_parquet_files():
    """Parquetãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª"""
    print("\n" + "=" * 80)
    print("Parquetãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª")
    print("=" * 80)

    parquet_files = [
        "keibaai/data/parsed/parquet/races/races.parquet",
        "keibaai/data/parsed/parquet/shutuba/shutuba.parquet",
        "keibaai/data/parsed/parquet/horses/horses.parquet",
        "keibaai/data/parsed/parquet/pedigrees/pedigrees.parquet",
    ]

    print("\nğŸ“Š ä¸»è¦ãªParquetãƒ•ã‚¡ã‚¤ãƒ«:\n")

    for file_path_str in parquet_files:
        file_path = Path(file_path_str)

        if file_path.exists():
            size_mb = file_path.stat().st_size / (1024 * 1024)
            mtime = datetime.fromtimestamp(file_path.stat().st_mtime)

            try:
                import pandas as pd
                df = pd.read_parquet(file_path)
                rows = len(df)
                cols = len(df.columns)
                status = f"âœ… {rows:,}è¡Œ Ã— {cols}åˆ— | {size_mb:.2f} MB | æ›´æ–°: {mtime.strftime('%Y-%m-%d %H:%M')}"
            except Exception as e:
                status = f"âš ï¸ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}"
        else:
            status = "âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“"

        print(f"{file_path.name:30s} -> {status}")

def check_metadata_db():
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿DBã®ç¢ºèª"""
    print("\n" + "=" * 80)
    print("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿DBã®ç¢ºèª")
    print("=" * 80)

    db_path = Path("keibaai/data/metadata/db.sqlite3")

    if not db_path.exists():
        print(f"\nâŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {db_path}")
        return

    print(f"\nâœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒå­˜åœ¨ã—ã¾ã™: {db_path}")
    print(f"   ã‚µã‚¤ã‚º: {db_path.stat().st_size / 1024:.2f} KB")

    try:
        import sqlite3
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = cursor.fetchall()

        print(f"\nğŸ“‹ ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ ({len(tables)}ä»¶):\n")

        for (table_name,) in tables:
            cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
            count = cursor.fetchone()[0]
            print(f"  - {table_name:30s} : {count:>10,} ãƒ¬ã‚³ãƒ¼ãƒ‰")

        conn.close()

    except Exception as e:
        print(f"\nâš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\n")
    print("ğŸ” KeibaAI_v2 ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ç¢ºèªãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print(f"â° å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("\n")

    # 1. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèª
    dir_results = check_directory_structure()

    # 2. RAW HTMLã‚µãƒ³ãƒ—ãƒ«ç¢ºèª
    check_raw_html_samples()

    # 3. Parquetãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    check_parquet_files()

    # 4. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿DBç¢ºèª
    check_metadata_db()

    # ã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 80)
    print("ğŸ“Š ã‚µãƒãƒªãƒ¼")
    print("=" * 80)

    raw_exists = any(
        dir_results.get(f"keibaai/data/raw/html/{t}", {}).get("exists", False)
        for t in ["race", "shutuba", "horse", "ped"]
    )

    parsed_exists = any(
        dir_results.get(f"keibaai/data/parsed/parquet/{t}", {}).get("exists", False)
        for t in ["races", "shutuba", "horses", "pedigrees"]
    )

    print(f"\nâœ… RAWãƒ‡ãƒ¼ã‚¿ï¼ˆHTMLï¼‰: {'å­˜åœ¨ã™ã‚‹' if raw_exists else 'å­˜åœ¨ã—ãªã„'}")
    print(f"âœ… ãƒ‘ãƒ¼ã‚¹æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ï¼ˆParquetï¼‰: {'å­˜åœ¨ã™ã‚‹' if parsed_exists else 'å­˜åœ¨ã—ãªã„'}")

    if raw_exists and not parsed_exists:
        print("\nğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: ãƒ‘ãƒ¼ã‚¹å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        print("   â†’ python keibaai/src/run_parsing_pipeline_local.py")
    elif not raw_exists:
        print("\nğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        print("   â†’ python keibaai/src/run_scraping_pipeline_local.py")
    elif parsed_exists:
        print("\nğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: ãƒ‡ãƒ¼ã‚¿ãŒæƒã£ã¦ã„ã¾ã™ã€‚ç‰¹å¾´é‡ç”Ÿæˆã‚„ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã«é€²ã‚ã¾ã™")

    print("\n" + "=" * 80)
    print("âœ… ãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ01å®Œäº†")
    print("=" * 80)
    print("\n")

if __name__ == "__main__":
    main()
