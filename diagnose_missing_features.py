"""
ç‰¹å¾´é‡ç”Ÿæˆã§è­¦å‘ŠãŒå‡ºãŸã‚«ãƒ©ãƒ ã®æ¬ æåŸå› ã‚’è¨ºæ–­ã—ã€å¯¾ç­–ã‚’æç¤º

ç‰¹å¾´é‡ç”Ÿæˆæ™‚ã®è­¦å‘Š:
  KeyError: "['passing_order_1', 'passing_order_4'] not in index"
  KeyError: "['venue'] not in index"
  KeyError: "['distance_category'] not in index"
  KeyError: "['track_surface'] not in index"
  KeyError: "['damsire_id'] not in index"
"""

from pathlib import Path
import pandas as pd
import yaml

def diagnose_missing_columns():
    print("=" * 80)
    print("ğŸ”§ ç‰¹å¾´é‡ç”Ÿæˆã®è­¦å‘Šè¨ºæ–­ãƒ„ãƒ¼ãƒ«")
    print("=" * 80)
    print()

    # --- ãƒ‘ãƒ¼ãƒˆ1: è­¦å‘ŠãŒå‡ºãŸã‚«ãƒ©ãƒ ã®ãƒªã‚¹ãƒˆ ---
    print("ğŸ“‹ è­¦å‘ŠãŒå‡ºãŸã‚«ãƒ©ãƒ :")
    print("-" * 80)

    missing_cols = {
        'passing_order_1': {
            'source': 'races.parquet',
            'type': 'ãƒ¬ãƒ¼ã‚¹çµæœã‹ã‚‰æŠ½å‡ºã™ã¹ã',
            'fix': 'results_parser.pyã§ passing_order ã‚’åˆ†å‰²'
        },
        'passing_order_4': {
            'source': 'races.parquet',
            'type': 'ãƒ¬ãƒ¼ã‚¹çµæœã‹ã‚‰æŠ½å‡ºã™ã¹ã',
            'fix': 'results_parser.pyã§ passing_order ã‚’åˆ†å‰²'
        },
        'venue': {
            'source': 'races.parquet',
            'type': 'ãƒ¬ãƒ¼ã‚¹çµæœã‹ã‚‰æŠ½å‡ºã™ã¹ã',
            'fix': 'results_parser.pyã§ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±ã‚’æŠ½å‡º'
        },
        'distance_category': {
            'source': 'æ´¾ç”Ÿç‰¹å¾´é‡',
            'type': 'distance_mã‹ã‚‰ç”Ÿæˆã™ã¹ã',
            'fix': 'feature_engine.pyã§ distance_m â†’ distance_categoryå¤‰æ›'
        },
        'track_surface': {
            'source': 'races.parquet',
            'type': 'ãƒ¬ãƒ¼ã‚¹çµæœã‹ã‚‰æŠ½å‡ºã™ã¹ã',
            'fix': 'results_parser.pyã§ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±ã‚’æŠ½å‡º'
        },
        'damsire_id': {
            'source': 'è¡€çµ±ãƒ‡ãƒ¼ã‚¿',
            'type': 'pedigrees.parquetã‹ã‚‰è¨ˆç®—ã™ã¹ã',
            'fix': 'feature_engine.pyã§ãƒãƒ¼ã‚¸æ™‚ã«æ¯çˆ¶ã‚’è¨ˆç®—'
        }
    }

    for col, info in missing_cols.items():
        print(f"  - {col:20} ({info['source']})")
    print()

    # --- ãƒ‘ãƒ¼ãƒˆ2: races.parquetã®ç¾çŠ¶ç¢ºèª ---
    print("=" * 80)
    print("ğŸ“Š ãƒ‘ãƒ¼ãƒˆ1: races.parquet ã®ç¾çŠ¶ç¢ºèª")
    print("=" * 80)
    print()

    races_path = Path('keibaai/data/parsed/parquet/races/races.parquet')

    if not races_path.exists():
        print(f"âŒ {races_path} ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        print("   â†’ ã¾ãšãƒ‘ãƒ¼ã‚¹å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return

    races_df = pd.read_parquet(races_path)
    print(f"âœ… races.parquet: {len(races_df):,} è¡Œ Ã— {len(races_df.columns)} åˆ—")
    print()

    # å¿…è¦ãªã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèª
    race_required = ['passing_order_1', 'passing_order_4', 'venue', 'track_surface', 'distance_m']

    print("ğŸ” å¿…è¦ã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèª:")
    print("-" * 80)
    for col in race_required:
        if col in races_df.columns:
            missing_pct = (races_df[col].isna().sum() / len(races_df)) * 100
            print(f"  âœ… {col:20} å­˜åœ¨ (æ¬ æ: {missing_pct:5.1f}%)")
        else:
            print(f"  âŒ {col:20} **å­˜åœ¨ã—ãªã„**")
    print()

    # passing_orderã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèª
    if 'passing_order' in races_df.columns:
        print("ğŸ’¡ passing_order ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ã¾ã™:")
        sample_value = races_df['passing_order'].iloc[0]
        print(f"   ã‚µãƒ³ãƒ—ãƒ«å€¤: {sample_value}")
        print(f"   ãƒ‡ãƒ¼ã‚¿å‹: {races_df['passing_order'].dtype}")
        print()
        print("   â†’ passing_order_1, passing_order_2... ã¸ã®åˆ†å‰²ãŒå¿…è¦ã§ã™")
        print("   â†’ results_parser.py ã® parse_passing_order() ã§å®Ÿè£…æ¸ˆã¿ã‹ã‚’ç¢ºèª")
    print()

    # --- ãƒ‘ãƒ¼ãƒˆ3: features.yamlã®è¨­å®šç¢ºèª ---
    print("=" * 80)
    print("ğŸ“Š ãƒ‘ãƒ¼ãƒˆ2: features.yaml ã®è¨­å®šç¢ºèª")
    print("=" * 80)
    print()

    features_yaml_path = Path('keibaai/configs/features.yaml')

    if not features_yaml_path.exists():
        print(f"âŒ {features_yaml_path} ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
    else:
        with open(features_yaml_path, 'r', encoding='utf-8') as f:
            features_config = yaml.safe_load(f)

        # past_performanceã®è¨­å®šç¢ºèª
        if 'feature_recipes' in features_config:
            past_perf = features_config['feature_recipes'].get('past_performance', {})
            if past_perf.get('enabled'):
                columns = past_perf.get('columns', [])
                print(f"âœ… past_performance.columns ã« {len(columns)} ã‚«ãƒ©ãƒ æŒ‡å®š:")
                for col in columns:
                    print(f"     - {col}")
                print()

                missing_in_config = [c for c in columns if c not in races_df.columns and not c.startswith('passing_order')]
                if missing_in_config:
                    print(f"   âš ï¸  ä»¥ä¸‹ã®ã‚«ãƒ©ãƒ ã¯ races.parquet ã«å­˜åœ¨ã—ã¾ã›ã‚“:")
                    for col in missing_in_config:
                        print(f"       - {col}")

            # interaction_featuresã®ç¢ºèª
            interaction = features_config['feature_recipes'].get('interaction_features', {})
            if interaction.get('enabled'):
                interactions = interaction.get('interactions', [])
                print()
                print(f"âœ… interaction_features ã« {len(interactions)} å€‹ã®äº¤äº’ä½œç”¨:")
                for inter in interactions:
                    context_col = inter.get('context_column')
                    if context_col == 'venue':
                        if 'venue' in races_df.columns:
                            print(f"     âœ… {inter['name']:20} (venue ä½¿ç”¨å¯èƒ½)")
                        else:
                            print(f"     âŒ {inter['name']:20} (venue **å­˜åœ¨ã—ãªã„**)")
                    elif context_col == 'distance_category':
                        print(f"     âš ï¸  {inter['name']:20} (distance_category ã¯æ´¾ç”Ÿç‰¹å¾´é‡)")
                    elif context_col == 'track_surface':
                        if 'track_surface' in races_df.columns:
                            print(f"     âœ… {inter['name']:20} (track_surface ä½¿ç”¨å¯èƒ½)")
                        else:
                            print(f"     âŒ {inter['name']:20} (track_surface **å­˜åœ¨ã—ãªã„**)")
        print()

    # --- ãƒ‘ãƒ¼ãƒˆ4: è¡€çµ±ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª ---
    print("=" * 80)
    print("ğŸ“Š ãƒ‘ãƒ¼ãƒˆ3: è¡€çµ±ãƒ‡ãƒ¼ã‚¿ (damsire_id) ã®ç¢ºèª")
    print("=" * 80)
    print()

    pedigrees_path = Path('keibaai/data/parsed/parquet/pedigrees/pedigrees.parquet')
    horses_path = Path('keibaai/data/parsed/parquet/horses/horses.parquet')

    if pedigrees_path.exists():
        pedigrees_df = pd.read_parquet(pedigrees_path)
        print(f"âœ… pedigrees.parquet: {len(pedigrees_df):,} è¡Œ")
        print(f"   ã‚«ãƒ©ãƒ : {', '.join(pedigrees_df.columns)}")
        print()

    if horses_path.exists():
        horses_df = pd.read_parquet(horses_path)
        print(f"âœ… horses.parquet: {len(horses_df):,} è¡Œ")
        print(f"   ã‚«ãƒ©ãƒ : {', '.join(horses_df.columns)}")
        print()

        if 'sire_id' in horses_df.columns:
            sire_missing = (horses_df['sire_id'].isna().sum() / len(horses_df)) * 100
            print(f"   âœ… sire_id å­˜åœ¨ (æ¬ æ: {sire_missing:.1f}%)")
        else:
            print(f"   âŒ sire_id **å­˜åœ¨ã—ãªã„**")

        if 'dam_id' in horses_df.columns:
            dam_missing = (horses_df['dam_id'].isna().sum() / len(horses_df)) * 100
            print(f"   âœ… dam_id  å­˜åœ¨ (æ¬ æ: {dam_missing:.1f}%)")
        else:
            print(f"   âŒ dam_id  **å­˜åœ¨ã—ãªã„**")

        if 'damsire_id' in horses_df.columns:
            damsire_missing = (horses_df['damsire_id'].isna().sum() / len(horses_df)) * 100
            print(f"   âœ… damsire_id å­˜åœ¨ (æ¬ æ: {damsire_missing:.1f}%)")
        else:
            print(f"   âŒ damsire_id **å­˜åœ¨ã—ãªã„**")
            print()
            print("   ğŸ’¡ damsire_id ã®ç”Ÿæˆæ–¹æ³•:")
            print("      1. pedigrees.parquet ã‹ã‚‰ dam_id ã®çˆ¶ã‚’æ¤œç´¢")
            print("      2. feature_engine.py ã®ãƒãƒ¼ã‚¸å‡¦ç†ã§è¿½åŠ ")

    print()

    # --- ãƒ‘ãƒ¼ãƒˆ5: å¯¾ç­–ã®æç¤º ---
    print("=" * 80)
    print("ğŸ“ å¯¾ç­–ã‚µãƒãƒªãƒ¼")
    print("=" * 80)
    print()

    fixes_needed = []

    # 1. passing_orderåˆ†å‰²
    if 'passing_order' in races_df.columns and 'passing_order_1' not in races_df.columns:
        fixes_needed.append({
            'priority': 1,
            'title': 'passing_order ã®åˆ†å‰²',
            'file': 'keibaai/src/modules/parsers/results_parser.py',
            'action': 'parse_passing_order() é–¢æ•°ã§ passing_order ã‚’ passing_order_1~4 ã«åˆ†å‰²',
            'code': """
# results_parser.py ã® parse_result_row() å†…ã§:
passing_str = columns[10].get_text(strip=True)  # "1-1-1-1"
if '-' in passing_str:
    orders = passing_str.split('-')
    for i, order in enumerate(orders, 1):
        row_data[f'passing_order_{i}'] = parse_int_or_none(order)
"""
        })

    # 2. venue, track_surfaceæŠ½å‡º
    if 'venue' not in races_df.columns or 'track_surface' not in races_df.columns:
        fixes_needed.append({
            'priority': 2,
            'title': 'venue, track_surface ã®æŠ½å‡º',
            'file': 'keibaai/src/modules/parsers/results_parser.py',
            'action': 'extract_race_metadata() ã§ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±ã‚’æŠ½å‡ºï¼ˆå®Ÿè£…æ¸ˆã¿ã®å¯èƒ½æ€§ã‚ã‚Šï¼‰',
            'note': 'CLAUDE.md ã«ã‚ˆã‚‹ã¨ã€æœ€è¿‘ã®ãƒ‘ãƒ¼ã‚µãƒ¼æ”¹å–„ã§å®Ÿè£…æ¸ˆã¿ã®ã¯ãšã€‚å†ãƒ‘ãƒ¼ã‚¹ãŒå¿…è¦ã‹ã‚‚ã€‚'
        })

    # 3. distance_categoryç”Ÿæˆ
    fixes_needed.append({
        'priority': 3,
        'title': 'distance_category ã®ç”Ÿæˆ',
        'file': 'keibaai/src/modules/features/feature_engine.py',
        'action': 'distance_m ã‹ã‚‰ distance_category ã‚’æ´¾ç”Ÿç‰¹å¾´é‡ã¨ã—ã¦ç”Ÿæˆ',
        'code': """
# feature_engine.py å†…ã§:
def create_distance_category(df):
    conditions = [
        df['distance_m'] <= 1400,
        (df['distance_m'] > 1400) & (df['distance_m'] <= 1800),
        (df['distance_m'] > 1800) & (df['distance_m'] <= 2200),
        df['distance_m'] > 2200
    ]
    choices = ['çŸ­è·é›¢', 'ãƒã‚¤ãƒ«', 'ä¸­è·é›¢', 'é•·è·é›¢']
    df['distance_category'] = pd.Series(pd.NA, dtype='object')
    df['distance_category'] = pd.Series(
        [choices[i] for i in range(len(choices)) for _ in range(len(df))
         if conditions[i].iloc[_]], dtype='category'
    )
    return df
"""
    })

    # 4. damsire_idç”Ÿæˆ
    if 'damsire_id' not in (horses_df.columns if horses_path.exists() and 'horses_df' in locals() else []):
        fixes_needed.append({
            'priority': 4,
            'title': 'damsire_id ã®ç”Ÿæˆ',
            'file': 'keibaai/src/modules/features/feature_engine.py',
            'action': 'pedigrees.parquet ã‹ã‚‰æ¯çˆ¶IDã‚’è¨ˆç®—ã—ã¦ãƒãƒ¼ã‚¸',
            'code': """
# feature_engine.py å†…ã§:
def add_damsire_id(df, pedigrees_df):
    # dam_id ã‚’æŒã¤ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã¿å‡¦ç†
    dam_pedigrees = pedigrees_df.rename(columns={'horse_id': 'dam_id', 'ancestor_id': 'damsire_id'})
    # æ¯ã®çˆ¶ï¼ˆ2ä¸–ä»£ç›®ã®çˆ¶å´ï¼‰ã‚’å–å¾—
    # ã“ã‚Œã¯ pedigree_parser ã®æ§‹é€ ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ç¢ºèªã—ã¦å®Ÿè£…
    df = df.merge(dam_pedigrees[['dam_id', 'damsire_id']], on='dam_id', how='left')
    return df
"""
        })

    # å¯¾ç­–ã‚’è¡¨ç¤º
    for i, fix in enumerate(fixes_needed, 1):
        print(f"[å¯¾ç­– {fix['priority']}] {fix['title']}")
        print(f"  ãƒ•ã‚¡ã‚¤ãƒ«: {fix['file']}")
        print(f"  å†…å®¹: {fix['action']}")
        if 'code' in fix:
            print(f"  å®Ÿè£…ä¾‹:")
            for line in fix['code'].strip().split('\n'):
                print(f"    {line}")
        if 'note' in fix:
            print(f"  ğŸ“ Note: {fix['note']}")
        print()

    print("=" * 80)
    print("âœ… è¨ºæ–­å®Œäº†")
    print("=" * 80)
    print()
    print("ğŸ“Œ æ¨å¥¨ã™ã‚‹ä½œæ¥­é †åº:")
    print("  1. races.parquet ã®å†ç¢ºèª (check_races_schema.py ã‚’å®Ÿè¡Œ)")
    print("  2. æ¬ æã‚«ãƒ©ãƒ ãŒãƒ‘ãƒ¼ã‚µãƒ¼ã§å®Ÿè£…æ¸ˆã¿ã‹ç¢ºèª")
    print("  3. å®Ÿè£…æ¸ˆã¿ãªã‚‰å†ãƒ‘ãƒ¼ã‚¹ã€æœªå®Ÿè£…ãªã‚‰ãƒ‘ãƒ¼ã‚µãƒ¼ä¿®æ­£")
    print("  4. distance_category ãªã©æ´¾ç”Ÿç‰¹å¾´é‡ã¯ feature_engine.py ã§è¿½åŠ ")
    print("  5. ä¿®æ­£å¾Œã€å†åº¦ç‰¹å¾´é‡ç”Ÿæˆã‚’å®Ÿè¡Œ")
    print()

if __name__ == '__main__':
    diagnose_missing_columns()
