#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†ç”Ÿæˆã•ã‚ŒãŸ Parquet ãƒ•ã‚¡ã‚¤ãƒ«ã®å“è³ªæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (validate_new_parquet.py)

v3 ä¿®æ­£ç‚¹:
1. (v2) `datetime` ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
2. (v2) 'sex' ã‚«ãƒ©ãƒ å­˜åœ¨ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ 
3. (v3) Test 4 ã®æˆåŠŸåˆ¤å®šã‚’ä¿®æ­£ (ã‚¨ãƒ©ãƒ¼ã§ None ãŒè¿”ã•ã‚ŒãŸå ´åˆã‚’ã€Œå¤±æ•—ã€ã¨ã™ã‚‹)
"""

import sys
import logging
from pathlib import Path
import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq
from datetime import datetime

# --- ãƒ­ã‚®ãƒ³ã‚°è¨­å®š ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] (%(filename)s:%(lineno)d) - %(message)s',
    stream=sys.stdout
)

# --- ãƒ‘ã‚¹è¨­å®š ---
PROJECT_ROOT = Path.cwd()
SRC_DIR = PROJECT_ROOT / 'keibaai' / 'src'
PARQUET_DIR = PROJECT_ROOT / 'keibaai' / 'data' / 'parsed' / 'parquet'

# --- (1) sys.path ã« 'keibaai/src' ã‚’è¿½åŠ  ---
if not SRC_DIR.exists():
    logging.error(f"ã‚¨ãƒ©ãƒ¼: `keibaai/src` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {SRC_DIR}")
    sys.exit(1)
sys.path.insert(0, str(SRC_DIR))
logging.info(f"`keibaai/src` ã‚’ sys.path ã«è¿½åŠ ã—ã¾ã—ãŸ: {SRC_DIR}")

# --- (2) data_utils ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
try:
    from utils.data_utils import load_parquet_data_by_date
    logging.info("utils.data_utils ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸã€‚")
except ImportError as e:
    logging.error(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    logging.error("`keibaai/src/utils/__init__.py` ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    sys.exit(1)

def validate_parquet_quality():
    """
    å†ç”Ÿæˆã•ã‚ŒãŸParquetãƒ•ã‚¡ã‚¤ãƒ«ã®å“è³ªã‚’æ¤œè¨¼ã™ã‚‹
    """
    logging.info("--- Parquet å“è³ªæ¤œè¨¼ é–‹å§‹ ---")
    all_tests_passed = True
    
    # === 1. races.parquet ã®æ¤œè¨¼ ===
    races_dir = PARQUET_DIR / "races" #
    if not races_dir.exists() or not any(races_dir.iterdir()):
        logging.warning(f"[è­¦å‘Š] races ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ç©ºã§ã™: {races_dir}")
        logging.warning("races ã®æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
    else:
        try:
            logging.info(f"ã‚¹ã‚­ãƒ¼ãƒèª­ã¿è¾¼ã¿ä¸­: {races_dir}")
            # (v3) Hiveå½¢å¼ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã‚¹ã‚­ãƒ¼ãƒã‚’èª­ã¿å–ã‚‹
            races_schema = pq.read_schema(next(races_dir.rglob("*.parquet")))
            race_date_type = races_schema.field('race_date').type
            
            if race_date_type == pa.date32():
                logging.info(f" [æˆåŠŸ] (Test 1) `races` ã® 'race_date' ã¯æœŸå¾…é€šã‚Šã® `date32` å‹ã§ã™ã€‚")
            else:
                logging.error(f" [å¤±æ•—] (Test 1) `races` ã® 'race_date' ã®å‹ãŒä¸æ­£ã§ã™ã€‚")
                all_tests_passed = False
                
        except Exception as e:
            logging.error(f" [å¤±æ•—] (Test 1) `races` ã®èª­ã¿è¾¼ã¿/æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            all_tests_passed = False

    # === 2. horses.parquet ã®æ¤œè¨¼ ===
    horses_dir = PARQUET_DIR / "horses" #
    if not horses_dir.exists() or not any(horses_dir.iterdir()):
        logging.warning(f"[è­¦å‘Š] horses ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ç©ºã§ã™: {horses_dir}")
        logging.warning("horses ã®æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
    else:
        try:
            logging.info(f"èª­ã¿è¾¼ã¿ä¸­: {horses_dir}")
            # (v3) Hiveå½¢å¼ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰DFã‚’èª­ã¿è¾¼ã‚€
            df_horses = pd.read_parquet(horses_dir)
            total_rows = len(df_horses)
            logging.info(f"`horses` ã‚’èª­ã¿è¾¼ã¿å®Œäº† (ç·è¡Œæ•°: {total_rows})")

            # (Test 2) æ—¥ä»˜ã®å‹ã‚’æ¤œè¨¼
            horses_schema = pq.read_schema(next(horses_dir.rglob("*.parquet")))
            birth_date_pa_type = horses_schema.field('birth_date').type

            if birth_date_pa_type == pa.date32():
                logging.info(f" [æˆåŠŸ] (Test 2) `horses` ã® 'birth_date' ã¯æœŸå¾…é€šã‚Šã® `date32` å‹ã§ã™ã€‚")
            else:
                logging.error(f" [å¤±æ•—] (Test 2) `horses` ã® 'birth_date' ã®å‹ãŒä¸æ­£ã§ã™ã€‚")
                all_tests_passed = False

            # (Test 3) ã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³ï¼ˆNULLè¡Œï¼‰ã®æ¤œè¨¼
            if 'sex' not in df_horses.columns:
                logging.warning(f" [è­¦å‘Š] (Test 3) `horses` ã« 'sex' ã‚«ãƒ©ãƒ ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            else:
                null_sex_count = df_horses['sex'].isnull().sum()
                if null_sex_count > 0:
                    logging.warning(f" [è­¦å‘Š] (Test 3) `horses` ã« 'sex' ãŒNULLã®è¡ŒãŒ {null_sex_count} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
                else:
                    logging.info(f" [æˆåŠŸ] (Test 3) `horses` ã« 'sex' ãŒNULLã®è¡Œã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        except KeyError as e:
            logging.error(f" [å¤±æ•—] (Test 2/3) `horses` ã®èª­ã¿è¾¼ã¿/æ¤œè¨¼ä¸­ã«ã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
            all_tests_passed = False
        except Exception as e:
            logging.error(f" [å¤±æ•—] (Test 2/3) `horses` ã®èª­ã¿è¾¼ã¿/æ¤œè¨¼ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            all_tests_passed = False
            
    # === 4. data_utils.py ã®æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿æ¤œè¨¼ ===
    if races_dir.exists():
        try:
            logging.info("--- (Test 4) data_utils.py ã®æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿æ¤œè¨¼ é–‹å§‹ ---")
            
            df_filtered = load_parquet_data_by_date(
                base_dir=races_dir, #
                start_dt=datetime(2023, 1, 1),
                end_dt=datetime(2023, 12, 31),
                date_col='race_date'
            )
            
            # === â–¼â–¼â–¼ ä¿®æ­£ç®‡æ‰€ (v3) â–¼â–¼â–¼ ===
            # (ã‚¨ãƒ©ãƒ¼æ™‚ã« None ãŒè¿”ã‚‹ã“ã¨ã‚’æ­£ã—ããƒã‚§ãƒƒã‚¯ã™ã‚‹)
            if df_filtered is not None:
                logging.info(f" [æˆåŠŸ] (Test 4) `load_parquet_data_by_date` ãŒæ­£å¸¸ã«å®Ÿè¡Œã•ã‚Œã¾ã—ãŸ (ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {len(df_filtered)}è¡Œ)ã€‚")
            else:
                # data_utils.py ãŒã‚¨ãƒ©ãƒ¼ã§ None ã‚’è¿”ã—ãŸå ´åˆ
                logging.error(f" [å¤±æ•—] (Test 4) `load_parquet_data_by_date` ãŒ None ã‚’è¿”ã—ã¾ã—ãŸã€‚(ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ)")
                all_tests_passed = False
            # === â–²â–²â–² ä¿®æ­£ç®‡æ‰€ â–²â–²â–² ===
                
        except Exception as e:
            logging.error(f" [å¤±æ•—] (Test 4) `load_parquet_data_by_date` ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            all_tests_passed = False
            
    # === çµæœã¾ã¨ã‚ ===
    logging.info("="*50)
    if all_tests_passed:
        logging.info("ğŸ‰ å…¨ã¦ã®å“è³ªæ¤œè¨¼ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸã€‚")
    else:
        logging.error("ğŸ”¥ ä¸€éƒ¨ã®å“è³ªæ¤œè¨¼ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    validate_parquet_quality()