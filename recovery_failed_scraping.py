#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŠ¹ç‡çš„ãªå†å–å¾—ãƒ»ãƒªã‚«ãƒãƒªãƒ¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å¤±æ•—ã—ãŸã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚„ãƒ‘ãƒ¼ã‚¹ã‚’åŠ¹ç‡çš„ã«å†å®Ÿè¡Œï¼š
1. ç©ºãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ç•°å¸¸ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œå‡º
2. ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆåŒ–
3. é¸æŠçš„ãªå†ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
4. å†ãƒ‘ãƒ¼ã‚¹å‡¦ç†
"""

import sys
from pathlib import Path
from collections import defaultdict
from datetime import datetime
import json
import argparse

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
project_root = Path(__file__).resolve().parent / "keibaai"
sys.path.append(str(project_root))

from src.modules.preparing import _scrape_html


class RecoveryManager:
    """ãƒªã‚«ãƒãƒªãƒ¼å‡¦ç†ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.html_dir = data_dir / "raw" / "html"
        self.failed_files = {
            'empty': [],
            'too_small': [],
            'parse_error': [],
        }

    def detect_failed_files(self, min_size: int = 1024):
        """å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º"""
        print("ğŸ” å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œå‡ºä¸­...")
        print("=" * 80)

        for file_type in ['race', 'shutuba', 'horse', 'ped']:
            dir_path = self.html_dir / file_type
            if not dir_path.exists():
                continue

            print(f"\nğŸ“ {file_type}ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
            files = list(dir_path.glob("*.bin"))

            empty_count = 0
            small_count = 0

            for file_path in files:
                size = file_path.stat().st_size

                # ç©ºãƒ•ã‚¡ã‚¤ãƒ«
                if size == 0:
                    self.failed_files['empty'].append({
                        'type': file_type,
                        'path': str(file_path),
                        'id': self._extract_id(file_path),
                        'size': 0
                    })
                    empty_count += 1

                # å°ã•ã™ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
                elif size < min_size:
                    self.failed_files['too_small'].append({
                        'type': file_type,
                        'path': str(file_path),
                        'id': self._extract_id(file_path),
                        'size': size
                    })
                    small_count += 1

            print(f"   ç©ºãƒ•ã‚¡ã‚¤ãƒ«: {empty_count:,}ä»¶")
            print(f"   å°ã•ã™ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ<{min_size}Bï¼‰: {small_count:,}ä»¶")

        # ã‚µãƒãƒªãƒ¼
        total_empty = len(self.failed_files['empty'])
        total_small = len(self.failed_files['too_small'])
        print("\n" + "=" * 80)
        print(f"ğŸ“Š æ¤œå‡ºçµæœ:")
        print(f"   ç©ºãƒ•ã‚¡ã‚¤ãƒ«: {total_empty:,}ä»¶")
        print(f"   å°ã•ã™ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«: {total_small:,}ä»¶")
        print(f"   åˆè¨ˆ: {total_empty + total_small:,}ä»¶")

    def _extract_id(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰IDã‚’æŠ½å‡º"""
        filename = file_path.stem
        # _ãŒã‚ã‚‹å ´åˆã¯åˆ†å‰²ï¼ˆé¦¬ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        if '_' in filename:
            return filename.split('_')[0]
        return filename

    def generate_recovery_list(self, output_path: Path):
        """ãƒªã‚«ãƒãƒªãƒ¼å¯¾è±¡ã®ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ"""
        print("\nğŸ“ ãƒªã‚«ãƒãƒªãƒ¼ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆä¸­...")

        recovery_list = {
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'data_directory': str(self.data_dir),
            },
            'summary': {
                'empty_files': len(self.failed_files['empty']),
                'too_small_files': len(self.failed_files['too_small']),
                'total': len(self.failed_files['empty']) + len(self.failed_files['too_small']),
            },
            'recovery_targets': {
                'race_ids': [],
                'horse_ids': [],
            },
            'details': self.failed_files,
        }

        # race_idã¨horse_idã«åˆ†é¡
        race_ids = set()
        horse_ids = set()

        for category in ['empty', 'too_small']:
            for file_info in self.failed_files[category]:
                file_type = file_info['type']
                file_id = file_info['id']

                if file_type in ['race', 'shutuba']:
                    race_ids.add(file_id)
                elif file_type in ['horse', 'ped']:
                    horse_ids.add(file_id)

        recovery_list['recovery_targets']['race_ids'] = sorted(list(race_ids))
        recovery_list['recovery_targets']['horse_ids'] = sorted(list(horse_ids))

        # ä¿å­˜
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(recovery_list, f, ensure_ascii=False, indent=2)

        print(f"ğŸ’¾ ãƒªã‚«ãƒãƒªãƒ¼ãƒªã‚¹ãƒˆã‚’ä¿å­˜: {output_path}")
        print(f"   ãƒ¬ãƒ¼ã‚¹ID: {len(race_ids):,}ä»¶")
        print(f"   é¦¬ID: {len(horse_ids):,}ä»¶")

        return recovery_list

    def delete_failed_files(self, dry_run: bool = True):
        """å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
        print("\nğŸ—‘ï¸  å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤")
        print("=" * 80)

        if dry_run:
            print("âš ï¸  DRY RUNãƒ¢ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã«ã¯å‰Šé™¤ã—ã¾ã›ã‚“ï¼‰\n")
        else:
            print("âš ï¸  å®Ÿéš›ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ï¼\n")

        total_deleted = 0
        total_size_freed = 0

        for category in ['empty', 'too_small']:
            print(f"\nâ–  {category}ãƒ•ã‚¡ã‚¤ãƒ«:")
            for file_info in self.failed_files[category]:
                file_path = Path(file_info['path'])
                size = file_info['size']

                if dry_run:
                    print(f"   [DRY RUN] å‰Šé™¤å¯¾è±¡: {file_path.name} ({size} bytes)")
                else:
                    try:
                        file_path.unlink()
                        print(f"   âœ… å‰Šé™¤: {file_path.name} ({size} bytes)")
                        total_deleted += 1
                        total_size_freed += size
                    except Exception as e:
                        print(f"   âŒ å‰Šé™¤å¤±æ•—: {file_path.name} - {e}")

        print("\n" + "=" * 80)
        if dry_run:
            print(f"[DRY RUN] å‰Šé™¤å¯¾è±¡: {len(self.failed_files['empty']) + len(self.failed_files['too_small']):,}ä»¶")
        else:
            print(f"âœ… å‰Šé™¤å®Œäº†: {total_deleted:,}ä»¶ï¼ˆ{self._format_size(total_size_freed)}è§£æ”¾ï¼‰")

    def _format_size(self, size: float) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if size < 1024:
            return f"{size:.0f} B"
        elif size < 1024 * 1024:
            return f"{size/1024:.1f} KB"
        else:
            return f"{size/(1024*1024):.2f} MB"


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description='å¤±æ•—ã—ãŸã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã®ãƒªã‚«ãƒãƒªãƒ¼',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã—ã¦ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ
  python %(prog)s --detect

  # å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆDRY RUNï¼‰
  python %(prog)s --detect --delete --dry-run

  # å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿéš›ã«å‰Šé™¤
  python %(prog)s --detect --delete

  # æœ€å°ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’æŒ‡å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1024ï¼‰
  python %(prog)s --detect --min-size 2048
        """
    )
    parser.add_argument('--detect', action='store_true', help='å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º')
    parser.add_argument('--delete', action='store_true', help='å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤')
    parser.add_argument('--dry-run', action='store_true', help='å‰Šé™¤ã®DRY RUNï¼ˆå®Ÿéš›ã«ã¯å‰Šé™¤ã—ãªã„ï¼‰')
    parser.add_argument('--min-size', type=int, default=1024, help='æœ€å°ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆbytesã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1024ï¼‰')

    args = parser.parse_args()

    print("ğŸ”§ KeibaAI_v2 ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»ãƒªã‚«ãƒãƒªãƒ¼ãƒ„ãƒ¼ãƒ«")
    print("=" * 80)

    data_dir = Path("keibaai/data")

    if not data_dir.exists():
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_dir}")
        return

    manager = RecoveryManager(data_dir)

    # å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œå‡º
    if args.detect:
        manager.detect_failed_files(min_size=args.min_size)

        # ãƒªã‚«ãƒãƒªãƒ¼ãƒªã‚¹ãƒˆç”Ÿæˆ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = data_dir / "logs" / "recovery" / f"recovery_list_{timestamp}.json"
        recovery_list = manager.generate_recovery_list(output_path)

        # å‰Šé™¤å‡¦ç†
        if args.delete:
            manager.delete_failed_files(dry_run=args.dry_run)

    else:
        print("âš ï¸  --detect ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
        parser.print_help()

    print("\n" + "=" * 80)
    print("âœ… å‡¦ç†å®Œäº†!")
    print("=" * 80)


if __name__ == "__main__":
    main()
