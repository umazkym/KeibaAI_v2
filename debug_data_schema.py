#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚­ãƒ¼ãƒè¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Phase D ã®ç‰¹å¾´é‡ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã‚«ãƒ©ãƒ åã®ä¸ä¸€è‡´ã‚’èª¿æŸ»
"""

import pandas as pd
from pathlib import Path
import sys

def inspect_parquet_schema(file_path, name):
    """Parquetãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒã‚’è¡¨ç¤º"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š {name}")
    print(f"{'='*80}")

    try:
        df = pd.read_parquet(file_path)
        print(f"è¡Œæ•°: {len(df):,}")
        print(f"ã‚«ãƒ©ãƒ æ•°: {len(df.columns)}")
        print(f"\nã‚«ãƒ©ãƒ ä¸€è¦§:")
        for i, col in enumerate(df.columns, 1):
            dtype = df[col].dtype
            null_count = df[col].isna().sum()
            null_pct = (null_count / len(df)) * 100 if len(df) > 0 else 0
            print(f"  {i:2d}. {col:30s} {str(dtype):15s} (NULL: {null_pct:5.1f}%)")

        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
        print(f"\nã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ (å…ˆé ­3è¡Œ):")
        print(df.head(3).to_string())

    except FileNotFoundError:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    data_path = Path("keibaai/data")

    print("="*80)
    print("KeibaAI_v2 ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚­ãƒ¼ãƒè¨ºæ–­")
    print("="*80)

    # 1. ãƒ¬ãƒ¼ã‚¹çµæœãƒ‡ãƒ¼ã‚¿ (results_history_df ã®ãƒ™ãƒ¼ã‚¹)
    races_file = data_path / "parsed/parquet/races/races.parquet"
    inspect_parquet_schema(races_file, "ãƒ¬ãƒ¼ã‚¹çµæœãƒ‡ãƒ¼ã‚¿ (races.parquet)")

    # 2. å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿
    shutuba_file = data_path / "parsed/parquet/shutuba/shutuba.parquet"
    inspect_parquet_schema(shutuba_file, "å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ (shutuba.parquet)")

    # 3. é¦¬æƒ…å ±ãƒ‡ãƒ¼ã‚¿
    horses_file = data_path / "parsed/parquet/horses/horses.parquet"
    inspect_parquet_schema(horses_file, "é¦¬æƒ…å ±ãƒ‡ãƒ¼ã‚¿ (horses.parquet)")

    # 4. è¡€çµ±ãƒ‡ãƒ¼ã‚¿
    pedigrees_file = data_path / "parsed/parquet/pedigrees/pedigrees.parquet"
    inspect_parquet_schema(pedigrees_file, "è¡€çµ±ãƒ‡ãƒ¼ã‚¿ (pedigrees.parquet)")

    # 5. æ—¢å­˜ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ« (ã‚‚ã—å­˜åœ¨ã™ã‚Œã°)
    features_dir = data_path / "features/parquet"
    if features_dir.exists():
        # æœ€æ–°ã®ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        parquet_files = list(features_dir.rglob("*.parquet"))
        if parquet_files:
            latest_features = max(parquet_files, key=lambda p: p.stat().st_mtime)
            inspect_parquet_schema(latest_features, f"æ—¢å­˜ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ ({latest_features.relative_to(data_path)})")

    print("\n" + "="*80)
    print("ğŸ” é‡è¦ãªèª¿æŸ»ãƒã‚¤ãƒ³ãƒˆ:")
    print("="*80)
    print("1. 'place' ã‚«ãƒ©ãƒ ã¯å­˜åœ¨ã™ã‚‹ã‹ï¼Ÿ â†’ ãŠãã‚‰ã 'venue' ã¾ãŸã¯ 'race_course'")
    print("2. 'sire_id' ã‚«ãƒ©ãƒ ã¯ pedigrees.parquet ã«å­˜åœ¨ã™ã‚‹ã‹ï¼Ÿ")
    print("3. generate_course_affinity_features ã§ä½¿ç”¨ã™ã‚‹ã‚«ãƒ©ãƒ :")
    print("   - ç«¶é¦¬å ´: 'place' â†’ å®Ÿéš›ã¯ï¼Ÿ")
    print("   - è·é›¢: 'distance_m' â†’ å­˜åœ¨ã™ã‚‹ï¼Ÿ")
    print("   - é¦¬å ´: 'track_surface' â†’ å­˜åœ¨ã™ã‚‹ï¼Ÿ")
    print("4. generate_race_condition_features ã§ä½¿ç”¨ã™ã‚‹ã‚«ãƒ©ãƒ :")
    print("   - 'head_count' (å‡ºèµ°é ­æ•°)")
    print("   - 'race_date' (æ—¥ä»˜)")
    print("   - 'prize' (è³é‡‘)")
    print("="*80)

if __name__ == "__main__":
    main()
