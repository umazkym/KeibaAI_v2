分析結果
出馬表データ（shutuba.parquet）には、2023 年 5 月 14 日の 1 日分のデータしか存在しないことが判明しました。

現状の整理

- 我々がこれまで学習に使ってきたデータは、すべてこの 2023 年 5 月 14 日のレースデータだったということになります。
- このままでは、学習に使ったデータと評価に使うデータを分けることができません。
- 同じデータで学習と評価を行うのは、「答えを見ながらテストを受ける」のと同じで、モデルの本当の実力（未知のデータへの予測能力）を正し
  く測ることができません。

全体の実行計画

長期間のデータを扱うため、プロセスを以下の 5 ステップに分けます。

- ステップ 1：データ収集（スクレイピング）
  netkeiba.com などから、指定された期間のレースに関連する全データ（レース結果、出馬表、馬情報など）の HTML を取得し、data/raw/に保存します。

- ステップ 2：データ整形（パース）
  ステップ 1 で収集した HTML を解析し、分析しやすい形式（Parquet）に変換して data/parsed/に保存します。

- ステップ 3：特徴量生成
  整形済みのデータから、AI が学習に使う「特徴量」を計算し、data/features/に保存します。データは学習用と評価用に分けます。

  - 学習用データ: 2020 年〜2023 年
  - 評価用データ: 2024 年

- ステップ 4：モデル再学習
  今回作成した train_mu_model.py を使い、4 年分の潤沢な学習用データで μ モデルを改めて学習させます。

- ステップ 5：モデル評価（バックテスト）
  学習に使っていない 2024 年の評価用データを使って、モデルの真の実力をテストします。

---

最初のステップと実行すべきコード

まずはステップ 1：データ収集（スクレイピング）から始めます。
そのために、データ収集のメインスクリプトである run_scraping_pipeline_local.py の使い方を確認します。

（調査中...）

調査の結果、run_scraping_pipeline_local.py は期間を引数として受け取ることが分かりました。
これを使い、データ収集を実行します。

【！！最重要：必ずお読みください！！】

- 時間: 5 年分という長期間のデータ収集は、数時間から、場合によっては数日かかる可能性があります。
- 負荷とリスク:
  短時間に大量のアクセスを行うと、対象サイトに大きな負荷をかけ、ご自身の IP アドレスがブロックされる（BAN される）リスクが非常に高いです。
- 推奨事項: そのため、一度に 5 年分を実行するのではなく、まずは 1 年分など、期間を区切って少しずつ実行することを強くお勧めします。

提案
まずは試しに 2020 年の 1 年間分のデータ収集から始めてはいかがでしょうか？
それでも十分な時間がかかりますし、プロセスが正常に完了するかを確認するのに適しています。

もし、2020 年分の収集でよろしければ、以下のコマンドを実行してください。

1 python keibaai/src/run_scraping_pipeline_local.py --start_date 2020-01-01 --end_date 2020-12-31

このコマンドの実行には時間がかかります。完了しましたら、お声がけください。
もし、それでも 5 年分を一気に実行したい場合は、その旨をお伝えください。ただし、上記のリスクをご承知おきください。
C:\Users\zk-ht\Keiba\Keiba_AI\data\html

相関分析の結果、核心的な問題が 3 つ明らかになりました。

1.  特徴量の予測能力が極めて低い:
    ほとんどの特徴量において、着順との相関係数の絶対値が 0.1 を下回っており、予測の根拠として非常に弱いことが判明しました。

2.  一部の特徴量の相関が逆転している:
    past\_...\_finish_time_seconds_mean（過去の平均タイム）が、着順と負の相関を示しています。これは「過去の平均タイムが速い（小さい）馬ほど、着順が悪い（大きい）」という直感に反する結果であり、モデルを積極的に混乱させている要因です。

3.  重要な特徴量が欠落している:
    prize_total（獲得賞金）、morning_odds（前日オッズ）、morning_popularity（前日人気）といった、本来予測に重要であるはずの特徴量が、分析結果で NaN（非数）となっていました。これは、特徴量として全く利用できていないことを意味します。

feature_engine.py のバグは修正しましたが、それは氷山の一角であり、より根深い問題、すなわち「特徴量そのものが壊れている、あるいは欠落している」という問題が露呈しました。

今後の進め方:

この状況を打開するため、特徴量生成のさらに上流、つまりパーサー（HTML から情報を抽出する部分）に問題がないかを確認する必要があります。特に、NaN となっている特徴量は、そもそもパースの段階で正しく抽出できていない可能性が非常に高いです。

新しい計画:

1.  パーサーの検証:
    prize_total や morning_odds などを抽出する役割を持つ keibaai/src/modules/parsers/shutuba_parser.py のコードを精査し、ロジックに誤りがないかを確認します。

2.  パーサーの修正:
    バグが発見された場合、それを修正します。

3.  パイプラインの再実行:
    パーサーを修正した場合、データの流れ全体（パース → 特徴量生成 → 学習 → 評価）を再度実行し、モデル性能が改善されるかを確認する必要があります。

まずは計画 1「パーサーの検証」から着手します。keibaai/src/modules/parsers/shutuba_parser.py を読み込みます。

分析結果（確定）

- race, shutuba フォルダ: ファイル名は {12 桁のレース ID}.bin
- ped フォルダ: ファイル名は {10 桁の馬 ID}.bin
- horse フォルダ: ファイル名は {10 桁の馬 ID}\_perf.bin または {10 桁の馬 ID}\_profile.bin

これらの形式は、現在のプログラムが想定するタイムスタンプ付きの形式とは異なります。

- Keiba_AI プロジェクトから、過去に収集した大量の生データ（HTML ファイル）を、現在の Keiba_AI_v2 プロジェクトにコピーしました。
  _ コピー元: C:\Users\zk-ht\Keiba\Keiba_AI\data\html
  _ コピー先: C:\Users\zk-ht\Keiba\Keiba_AI_v2\keibaai\data\raw\html

現在の課題
コピーしたデータのファイル名の形式が、現在のプログラムが想定している形式と異なる可能性が高いです。このままでは、次の「ステップ 2：デ
ータ整形（パース）」でエラーが発生してしまいます。

これからやること
ご指示の通り、コピーされたデータがどのようなファイル名で、どのような中身なのかを詳しく調査します。
この調査結果をもとに、データ整形プログラム（パーサー）をどう修正すればよいかの最終的な計画を立てます。

---

データ確認の実行

それでは、これから horse, ped, race, shutuba の各フォルダについて、ファイル名と中身の確認を行います。

1. ファイル名の確認
   まず、各フォルダにどのようなファイル名でデータが保存されているか、一覧で確認します。
