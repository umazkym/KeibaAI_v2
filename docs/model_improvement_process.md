# KeibaAI プロジェクト：モデル改善と基盤強化の全記録

## 1. プロジェクトの背景と目的

### 1.1. 現状の課題
本プロジェクトは、競馬予測AI「KeibaAI」の運用において、以下の2つの大きな壁に直面していました。
1.  **収益性の欠如**: 初期のベースラインモデルでは、単勝回収率（ROI）が **42.38%** に留まり、実運用に耐えうる水準（目標100%超）から大きく乖離していました。
2.  **データ基盤の脆弱性**: 過去数年分の膨大なレースデータを処理する過程で、原因不明のエラーが頻発し、モデルの再学習や検証がスムーズに行えない状態でした。

### 1.2. 目的
本フェーズの目的は、単なるモデルのチューニングに留まらず、**「信頼できるデータ基盤の構築」**と**「統計的根拠に基づく収益モデルの確立」**を同時に達成することでした。

---

## 2. 改善プロセスの詳細経緯

### Phase A: データ基盤の修復 (The Data Integrity Crisis)

#### 直面した問題：Parquetメタデータ破損
2020年から2023年の学習データをロードしようとした際、`pyarrow.lib.ArrowInvalid` というエラーが発生し、パイプラインが完全に停止しました。
調査の結果、一部のParquetファイルのメタデータ（統計情報）に、予期せぬ**全角文字**や不正なバイナリデータが混入していることが判明しました。これは、スクレイピング時のエンコーディング処理の不備に起因するものでした。

#### 解決策：堅牢なローディングロジックの実装
既存のライブラリ（PyArrow Dataset）はメタデータを厳密にチェックするため、このエラーを回避できませんでした。そこで、以下の対策を実施しました。
1.  **ローダーの刷新**: `data_utils.py` を書き換え、メタデータに依存する高速読み込みを廃止し、Pandasを用いて各ファイルを個別に読み込む「堅牢性重視」のロジックに変更しました。
2.  **エンコーディング対応**: Windows環境特有の `cp932` エンコーディング問題を解決するため、サブプロセス呼び出し時の文字コード指定を修正しました。

#### 成果
これにより、**430日分、約18万レース**のデータが欠損なく利用可能となり、モデル改善の土台が整いました。

---

### Phase B: 予測精度の飛躍的向上 (Model Optimization)

#### 初期の試みと限界
データが揃った段階で学習させた初期モデル（LightGBMデフォルト設定）のバックテスト結果は、ROI **42.38%** でした。これは、単に「人気馬」を予測する傾向が強く、オッズの低い馬ばかりを推奨してしまうため、控除率（約20%）の影響をモロに受けていたことが原因です。

#### 施策：Optunaによるハイパーパラメータ最適化
この限界を突破するため、**Optuna**を用いた自動ハイパーパラメータ探索を導入しました。

1.  **評価指標の厳格化**:
    *   通常のK-Fold交差検証ではなく、時系列データの順序を守る **Time Series Cross-Validation** を採用し、未来の情報をリークさせない厳格な評価環境を構築しました。
2.  **探索空間の設計**:
    *   モデルの過学習を防ぎつつ表現力を高めるため、`num_leaves`（木の複雑さ）、`learning_rate`（学習率）、`feature_fraction`（特徴量の採用率）などを重点的に調整しました。
3.  **実行結果**:
    *   20回の試行（トライアル）を経て、RMSE（二乗平均平方根誤差）を最小化する最適なパラメータセットを発見しました。

#### 成果：ROI +20% の衝撃
最適化されたパラメータで再学習を行い、2024年のデータでバックテストを実施した結果、ROIは **62.69%** まで向上しました。
これは、ベースラインから **+20.31ポイント** の改善であり、モデルが「単に当てる」だけでなく「より確度の高い波乱」を捉え始めたことを示唆しています。

---

### Phase C: 投資戦略の転換 (Strategic Shift)

#### 「当てる」から「稼ぐ」へ
ROI 62%は大きな進歩ですが、100%には届いていません。ここで、アプローチを根本的に変える決断をしました。
**「的中率（Accuracy）を追うのをやめ、期待値（Expected Value）を追う」**という戦略転換です。

#### 新たな運用フレームワーク
1.  **期待値フィルタリング**:
    *   AIの予測勝率とオッズを掛け合わせた「期待値」が 1.0 を超える馬のみを狙う戦略を導入。これにより、過剰人気馬（勝つ確率は高いが儲からない馬）を自動的に排除します。
2.  **人間とAIの協調 (Human-in-the-loop)**:
    *   数値データだけでは捉えきれない「定性情報（騎手の心理、当日の馬場気配など）」を補完するため、**LLM（大規模言語モデル）**を分析パートナーとして採用。
    *   AIが弾き出した「数値」に対し、LLMが「なぜその評価なのか」という解釈を与え、最終的に人間が投資判断を下すプロセスを設計しました。

---

## 3. 結論と今後の展望

本プロジェクトは、データ基盤の修復という「守り」の施策から始まり、モデル最適化という「攻め」の施策を経て、現在は投資戦略の高度化という「応用」のフェーズにあります。

今後のロードマップ：
1.  **特徴量の拡張**: 騎手・調教師データ、血統情報の追加による予測精度の底上げ。
2.  **アンサンブル学習**: LightGBM以外のモデル（XGBoost, Neural Network）との組み合わせによる安定化。
3.  **資金管理の最適化**: ケリー基準などを応用した、自信度に応じたベット額の調整。

これらの施策を通じて、ROI 100%超えの実現を目指します。
