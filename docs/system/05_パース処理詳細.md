# 05_ãƒ‘ãƒ¼ã‚¹å‡¦ç†è©³ç´°

**æœ€çµ‚æ›´æ–°æ—¥**: 2025-11-18

---

## ğŸ“‘ ç›®æ¬¡

1. [ãƒ‘ãƒ¼ã‚¹å‡¦ç†æ¦‚è¦](#ãƒ‘ãƒ¼ã‚¹å‡¦ç†æ¦‚è¦)
2. [4ç¨®é¡ã®ãƒ‘ãƒ¼ã‚µãƒ¼](#4ç¨®é¡ã®ãƒ‘ãƒ¼ã‚µãƒ¼)
3. [HTMLè§£æãƒ‘ã‚¿ãƒ¼ãƒ³](#htmlè§£æãƒ‘ã‚¿ãƒ¼ãƒ³)
4. [å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£](#å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£)
5. [ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°](#ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°)
6. [ãƒ‡ãƒ¼ã‚¿å“è³ªæ”¹å–„ã®æ­´å²](#ãƒ‡ãƒ¼ã‚¿å“è³ªæ”¹å–„ã®æ­´å²)

---

## ğŸ”„ ãƒ‘ãƒ¼ã‚¹å‡¦ç†æ¦‚è¦

### å¤‰æ›ãƒ—ãƒ­ã‚»ã‚¹

```
data/raw/html/*.bin (EUC-JP encoded HTML)
    â†“
BeautifulSoup('html.parser')  # âš ï¸ 'lxml'ã§ã¯ãªã„
    â†“
DOM tree navigation
    â†“
pandas DataFrame
    â†“
Type conversion (Int64, float32, etc.)
    â†“
data/parsed/parquet/*.parquet
```

### ãƒ‘ãƒ¼ã‚µãƒ¼ä¸€è¦§

| ãƒ‘ãƒ¼ã‚µãƒ¼ | å…¥åŠ› | å‡ºåŠ› | ã‚µã‚¤ã‚º |
|---------|------|------|-------|
| `results_parser.py` | `race/{race_id}.bin` | `races.parquet` | 14KB |
| `shutuba_parser.py` | `shutuba/{race_id}.bin` | `shutuba.parquet` | 14KB |
| `horse_info_parser.py` | `horse/{horse_id}_*.bin` | `horses.parquet` | 16KB |
| `pedigree_parser.py` | `ped/{horse_id}.bin` | `pedigrees.parquet` | 9KB |

---

## ğŸ‡ 4ç¨®é¡ã®ãƒ‘ãƒ¼ã‚µãƒ¼

### 1. results_parser.pyï¼ˆãƒ¬ãƒ¼ã‚¹çµæœï¼‰

**ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: `keibaai/src/modules/parsers/results_parser.py`

#### ãƒ¡ã‚¤ãƒ³é–¢æ•°

```python
def parse_results_html(file_path: str, race_id: str = None) -> pd.DataFrame:
    """
    ãƒ¬ãƒ¼ã‚¹çµæœHTMLã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦DataFrameã‚’è¿”ã™

    Args:
        file_path: .binãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        race_id: ãƒ¬ãƒ¼ã‚¹IDï¼ˆNoneã®å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æŠ½å‡ºï¼‰

    Returns:
        pd.DataFrame: 27+åˆ—ã®ãƒ¬ãƒ¼ã‚¹çµæœ
    """
```

#### å‡¦ç†ãƒ•ãƒ­ãƒ¼

```python
# Step 1: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆEUC-JPãƒ‡ã‚³ãƒ¼ãƒ‰ï¼‰
with open(file_path, 'rb') as f:
    html_bytes = f.read()

try:
    html_text = html_bytes.decode('euc_jp', errors='replace')
except:
    html_text = html_bytes.decode('utf-8', errors='replace')

# Step 2: BeautifulSoupãƒ‘ãƒ¼ã‚¹
soup = BeautifulSoup(html_text, 'html.parser')  # âš ï¸ html.parserã‚’ä½¿ç”¨

# Step 3: ãƒ¬ãƒ¼ã‚¹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆ4æ®µéšãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
race_metadata = extract_race_metadata_enhanced(soup)

# Step 4: çµæœãƒ†ãƒ¼ãƒ–ãƒ«æŠ½å‡º
result_table = soup.find('table', class_='race_table_01')

# Step 5: å„è¡Œã‚’ãƒ‘ãƒ¼ã‚¹
rows = []
for tr in result_table.find_all('tr'):
    row_data = parse_result_row_enhanced(tr, race_id, race_date, race_metadata)
    rows.append(row_data)

# Step 6: DataFrameåŒ– + æ´¾ç”Ÿç‰¹å¾´é‡
df = pd.DataFrame(rows)
df = add_derived_features(df)

# Step 7: å‹å¤‰æ›ï¼ˆnullable integerï¼‰
df = convert_dtypes(df)

return df
```

#### 4æ®µéšãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆè·é›¢ãƒ»é¦¬å ´æŠ½å‡ºï¼‰

```python
def extract_race_metadata_enhanced(soup: BeautifulSoup) -> Dict:
    # Level 1: data_intro > diary_snap_cut > span
    race_data = soup.find('div', class_='data_intro')
    if race_data:
        snap_cut = race_data.find('div', class_='diary_snap_cut')
        if snap_cut:
            span = snap_cut.find('span')
            if span:
                text = span.get_text()
                # "ãƒ€1200m / å¤©å€™:æ™´ / ãƒ€ãƒ¼ãƒˆ:è‰¯ / ç™ºèµ°:10:10"
                match = re.search(r'(èŠ|ãƒ€|éšœ)\s*(?:å³|å·¦|ç›´|å¤–|å†…)?\s*(\d+)m', text)
                if match:
                    return extract_distance_surface(match)

    # Level 2: data_intro > spanï¼ˆç›´æ¥ï¼‰
    if race_data:
        span = race_data.find('span')
        if span:
            # ...åŒæ§˜ã®å‡¦ç†

    # Level 3: dl.racedata > dd
    race_data_dl = soup.find('dl', class_='racedata')
    if race_data_dl:
        dd = race_data_dl.find('dd')
        if dd:
            # ...åŒæ§˜ã®å‡¦ç†

    # Level 4: ãƒšãƒ¼ã‚¸å…¨ä½“ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢
    page_text = soup.get_text()
    match = re.search(r'(èŠ|ãƒ€|éšœ)\s*(\d+)m', page_text)
    if match:
        return extract_distance_surface(match)

    # ã™ã¹ã¦å¤±æ•—
    logging.warning(f"Failed to extract race metadata")
    return {'distance_m': None, 'track_surface': None, ...}
```

#### trainer_id, owner_name ã®å …ç‰¢ãªæŠ½å‡º

```python
def parse_result_row_enhanced(tr, race_id, race_date, race_metadata):
    cells = tr.find_all('td')

    # åˆ—æ•°ã«å¿œã˜ãŸæŸ”è»Ÿãªå‡¦ç†
    if len(cells) >= 18:
        # é€šå¸¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        trainer_idx = 15
        owner_idx = 16
        prize_idx = 17

        # è³é‡‘ãŒã‚ã‚‹ã‹ï¼ˆ1ç€ã®ã¿ï¼‰
        if cells[prize_idx].get_text(strip=True).replace(',', '').isdigit():
            # è³é‡‘åˆ—ãŒå­˜åœ¨
            pass
        else:
            # è³é‡‘åˆ—ãŒãªã„ â†’ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª¿æ•´
            owner_idx = 17

        # èª¿æ•™å¸«
        trainer_cell = cells[trainer_idx]
        trainer_link = trainer_cell.find('a')
        if trainer_link:
            trainer_id = get_id_from_href(trainer_link.get('href'), 'trainer')
            trainer_name = trainer_link.get_text(strip=True)

        # é¦¬ä¸»
        owner_cell = cells[owner_idx]
        owner_text = owner_cell.get_text(strip=True)
        if owner_text and owner_text not in ['---', '']:
            owner_name = normalize_owner_name(owner_text)

    return {
        'trainer_id': trainer_id,
        'trainer_name': trainer_name,
        'owner_name': owner_name,
        ...
    }
```

---

### 2. shutuba_parser.pyï¼ˆå‡ºé¦¬è¡¨ï¼‰

**ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: `keibaai/src/modules/parsers/shutuba_parser.py`

#### ä¸»è¦æŠ½å‡ºé …ç›®

```python
def parse_shutuba_html(file_path: str, race_id: str = None) -> pd.DataFrame:
    """
    å‡ºé¦¬è¡¨HTMLã‚’ãƒ‘ãƒ¼ã‚¹

    æŠ½å‡ºé …ç›®:
    - race_id, race_date
    - bracket_number, horse_number
    - horse_id, horse_name
    - sex, age
    - basis_weight
    - jockey_id, jockey_name
    - trainer_id, trainer_name
    - horse_weight, horse_weight_change
    - morning_odds, morning_popularity
    - blinkers (ãƒ–ãƒªãƒ³ã‚«ãƒ¼è£…ç€ãƒ•ãƒ©ã‚°)
    - prediction_mark (äºˆæƒ³å°: â—â—‹â–²â–³â˜†)
    - scratched (å–æ¶ˆãƒ•ãƒ©ã‚°)
    """
```

#### ãƒ–ãƒªãƒ³ã‚«ãƒ¼æŠ½å‡º

```html
<td class="HorseInfo">
  <a href="/horse/2017102294/">ã‚ªãƒ¡ã‚¬ãƒ¬ã‚¤ãƒ³ãƒœãƒ¼</a>
  <span class="Blinker">B</span>  <!-- ãƒ–ãƒªãƒ³ã‚«ãƒ¼ -->
</td>
```

```python
horse_info_cell = tr.find('td', class_='HorseInfo')
blinker_span = horse_info_cell.find('span', class_='Blinker')
blinkers = blinker_span is not None  # True or False
```

#### äºˆæƒ³å°æŠ½å‡º

```html
<td>
  <span class="Icon_Mark">â—</span>  <!-- æœ¬å‘½å° -->
</td>
```

```python
mark_span = td_cell.find('span', class_='Icon_Mark')
prediction_mark = mark_span.get_text(strip=True) if mark_span else None
# "â—"æœ¬å‘½ / "â—‹"å¯¾æŠ— / "â–²"å˜ç©´ / "â–³"é€£ä¸‹ / "â˜†"
```

---

### 3. horse_info_parser.pyï¼ˆé¦¬ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒ»éå»æˆç¸¾ï¼‰

**ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: `keibaai/src/modules/parsers/horse_info_parser.py`

#### 2ç¨®é¡ã®é–¢æ•°

```python
def parse_horse_profile(file_path: str, horse_id: str) -> pd.DataFrame:
    """
    é¦¬ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒšãƒ¼ã‚¸ã‚’ãƒ‘ãƒ¼ã‚¹

    æŠ½å‡ºé …ç›®:
    - horse_id, horse_name
    - birth_date, sex, coat_color
    - trainer_id, trainer_name
    - owner_name, breeder_name, producing_area
    - sire_id, sire_name, dam_id, dam_name, damsire_id, damsire_name
    - height_cm, chest_girth_cm, cannon_bone_cm
    - sale_price
    """

def parse_horse_performance(soup: BeautifulSoup, horse_id: str) -> pd.DataFrame:
    """
    é¦¬éå»æˆç¸¾ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹

    æŠ½å‡ºé …ç›®ï¼ˆå„ãƒ¬ãƒ¼ã‚¹ã”ã¨ï¼‰:
    - horse_id, race_date, venue, weather
    - race_number, race_name, race_id
    - head_count, bracket_number, horse_number
    - finish_position, jockey_name, basis_weight
    - distance_m, track_surface
    - finish_time_seconds, margin_seconds
    - passing_order_{1,2,3,4}
    - last_3f_time, win_odds, popularity
    - horse_weight, horse_weight_change
    """
```

#### é¦¬ä½“æƒ…å ±ã®æŠ½å‡º

```html
<table class="db_prof_table">
  <tr>
    <th>é¦¬ä½“é«˜(cm)</th>
    <td>156</td>
  </tr>
  <tr>
    <th>èƒ¸å›²(cm)</th>
    <td>183</td>
  </tr>
  <tr>
    <th>ç®¡å›²(cm)</th>
    <td>20.5</td>
  </tr>
</table>
```

```python
prof_table = soup.find('table', class_='db_prof_table')
rows = prof_table.find_all('tr')

for row in rows:
    th = row.find('th')
    td = row.find('td')
    label = th.get_text(strip=True)
    value_text = td.get_text(strip=True)

    if 'é¦¬ä½“é«˜' in label:
        height_cm = int(value_text)
    elif 'èƒ¸å›²' in label:
        chest_girth_cm = int(value_text)
    elif 'ç®¡å›²' in label:
        cannon_bone_cm = float(value_text)
```

---

### 4. pedigree_parser.pyï¼ˆè¡€çµ±ï¼‰

**ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: `keibaai/src/modules/parsers/pedigree_parser.py`

#### 5ä¸–ä»£è¡€çµ±ã®ãƒ‘ãƒ¼ã‚¹

```python
def parse_pedigree_html(file_path: str, horse_id: str) -> pd.DataFrame:
    """
    è¡€çµ±HTMLã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆ5ä¸–ä»£ï¼‰

    å‡ºåŠ›å½¢å¼:
    | horse_id | generation | ancestor_id | ancestor_name | ancestor_birth_year | ancestor_coat_color |
    |----------|------------|-------------|---------------|---------------------|---------------------|
    | 2020104567 | 1 | 2012100123 | ãƒ‡ã‚£ãƒ¼ãƒ—ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ | 2002 | é¹¿æ¯› |
    | 2020104567 | 1 | 2010105678 | ãƒ­ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚µãƒƒãƒˆ | 2010 | é¹¿æ¯› |
    | 2020104567 | 2 | 1999100001 | Sunday Silence | 1986 | é¹¿æ¯› |
    | ... | ... | ... | ... | ... | ... |

    åˆè¨ˆ: 2 + 4 + 8 + 16 + 32 = 62è¡Œ/é¦¬
    """
```

#### HTMLæ§‹é€ 

```html
<table class="blood_table">
  <tr>
    <!-- Generation 1: çˆ¶ -->
    <td rowspan="16">
      <a href="/horse/2012100123/">ãƒ‡ã‚£ãƒ¼ãƒ—ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ</a><br>
      <span class="red">2002 é¹¿æ¯›</span>
    </td>

    <!-- Generation 2: çˆ¶çˆ¶ -->
    <td rowspan="8">
      <a href="/horse/1999100001/">Sunday Silence</a><br>
      <span>1986 é¹¿æ¯›</span>
    </td>

    <!-- Generation 3: çˆ¶çˆ¶çˆ¶ -->
    <td rowspan="4">
      <a href="/horse/...">Halo</a><br>
      <span>1969 é»’é¹¿æ¯›</span>
    </td>

    <!-- ... ä»¥ä¸‹ã€Generation 4, 5 ã¨ç¶šã -->
  </tr>
</table>
```

#### å†å¸°çš„ãƒ‘ãƒ¼ã‚¹

```python
def parse_blood_table_recursive(soup, horse_id):
    blood_table = soup.find('table', class_='blood_table')

    pedigree_records = []

    # rowspanå±æ€§ã‹ã‚‰Generationåˆ¤å®š
    # rowspan=16 â†’ Gen 1
    # rowspan=8  â†’ Gen 2
    # rowspan=4  â†’ Gen 3
    # rowspan=2  â†’ Gen 4
    # rowspan=1  â†’ Gen 5

    for td in blood_table.find_all('td'):
        rowspan = int(td.get('rowspan', 1))
        generation = calculate_generation_from_rowspan(rowspan)

        link = td.find('a', href=re.compile(r'/horse/'))
        if link:
            ancestor_id = get_id_from_href(link.get('href'), 'horse')
            ancestor_name = link.get_text(strip=True)

        span = td.find('span')
        if span:
            text = span.get_text(strip=True)
            # "2002 é¹¿æ¯›"
            match = re.match(r'(\d{4})\s+(\S+)', text)
            if match:
                ancestor_birth_year = int(match.group(1))
                ancestor_coat_color = match.group(2)

        pedigree_records.append({
            'horse_id': horse_id,
            'generation': generation,
            'ancestor_id': ancestor_id,
            'ancestor_name': ancestor_name,
            'ancestor_birth_year': ancestor_birth_year,
            'ancestor_coat_color': ancestor_coat_color
        })

    return pd.DataFrame(pedigree_records)
```

---

## ğŸ§© HTMLè§£æãƒ‘ã‚¿ãƒ¼ãƒ³

### ãƒ‘ã‚¿ãƒ¼ãƒ³1: BeautifulSoupåŸºæœ¬

```python
soup = BeautifulSoup(html_text, 'html.parser')

# ã‚¿ã‚°æ¤œç´¢
table = soup.find('table', class_='race_table_01')

# è¤‡æ•°ã‚¿ã‚°æ¤œç´¢
rows = soup.find_all('tr')

# å±æ€§å–å¾—
href = link.get('href')
rowspan = td.get('rowspan', 1)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤æŒ‡å®š

# ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
text = td.get_text(strip=True)  # å‰å¾Œã®ç©ºç™½å‰Šé™¤
```

### ãƒ‘ã‚¿ãƒ¼ãƒ³2: æ­£è¦è¡¨ç¾

```python
import re

# URL ã‹ã‚‰IDæŠ½å‡º
match = re.search(r'/horse/(\w+)/', href)
horse_id = match.group(1) if match else None

# ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ•°å€¤æŠ½å‡º
match = re.search(r'(\d+)m', text)
distance_m = int(match.group(1)) if match else None

# è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³
match = re.search(r'(\d+)å›(\S+?)(\d+)æ—¥ç›®', text)
if match:
    round_of_year = int(match.group(1))
    venue = match.group(2)
    day_of_meeting = int(match.group(3))
```

### ãƒ‘ã‚¿ãƒ¼ãƒ³3: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

```python
# è¤‡æ•°ã®æŠ½å‡ºæ–¹æ³•ã‚’è©¦ã™
value = None

# æ–¹æ³•1
elem = soup.find('div', class_='primary')
if elem:
    value = elem.get_text(strip=True)

# æ–¹æ³•2ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
if not value:
    elem = soup.find('span', class_='secondary')
    if elem:
        value = elem.get_text(strip=True)

# æ–¹æ³•3ï¼ˆæœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
if not value:
    elem = soup.find('p')
    if elem:
        value = elem.get_text(strip=True)
```

---

## ğŸ› ï¸ å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

**ãƒ•ã‚¡ã‚¤ãƒ«**: `keibaai/src/modules/parsers/common_utils.py`

### parse_time_to_seconds()

```python
def parse_time_to_seconds(time_str: str) -> Optional[float]:
    """
    ã‚¿ã‚¤ãƒ æ–‡å­—åˆ—ã‚’ç§’æ•°ã«å¤‰æ›

    Examples:
        "1:23.4" â†’ 83.4
        "59.8" â†’ 59.8
        "2:00.0" â†’ 120.0
    """
    if not time_str or time_str.strip() in ['', '-']:
        return None

    try:
        # "1:23.4" å½¢å¼
        if ':' in time_str:
            parts = time_str.split(':')
            minutes = int(parts[0])
            seconds = float(parts[1])
            return minutes * 60 + seconds
        # "59.8" å½¢å¼
        else:
            return float(time_str)
    except ValueError:
        return None
```

### parse_margin_to_seconds()

```python
def parse_margin_to_seconds(margin_str: str) -> Optional[float]:
    """
    ç€å·®æ–‡å­—åˆ—ã‚’ç§’æ•°ã«å¤‰æ›

    Examples:
        "3" â†’ 0.6ç§’ï¼ˆ3é¦¬èº« = 3 * 0.2ï¼‰
        "1 1/2" â†’ 0.3ç§’ï¼ˆ1.5é¦¬èº«ï¼‰
        "ã‚¯ãƒ“" â†’ 0.02ç§’
        "ãƒãƒŠ" â†’ 0.01ç§’
        "ã‚¢ã‚¿ãƒ" â†’ 0.05ç§’
    """
    if not margin_str or margin_str.strip() in ['', '-']:
        return None

    # ç‰¹æ®Šã‚±ãƒ¼ã‚¹
    special_cases = {
        'ãƒãƒŠ': 0.01,
        'ã‚¯ãƒ“': 0.02,
        'ã‚¢ã‚¿ãƒ': 0.05,
        'åŒç€': 0.0
    }

    for key, value in special_cases.items():
        if key in margin_str:
            return value

    # é¦¬èº«æ›ç®—ï¼ˆ1é¦¬èº« = 0.2ç§’ï¼‰
    try:
        # "3" â†’ 3.0
        if margin_str.isdigit():
            return float(margin_str) * 0.2

        # "1 1/2" â†’ 1.5 â†’ 0.3
        if ' ' in margin_str:
            parts = margin_str.split()
            integer_part = int(parts[0])
            fraction_part = eval(parts[1])  # "1/2" â†’ 0.5
            total_bodies = integer_part + fraction_part
            return total_bodies * 0.2

        return None

    except:
        return None
```

### parse_sex_age()

```python
def parse_sex_age(sex_age_str: str) -> Tuple[Optional[str], Optional[int]]:
    """
    æ€§é½¢æ–‡å­—åˆ—ã‚’åˆ†è§£

    Examples:
        "ç‰¡3" â†’ ("ç‰¡", 3)
        "ç‰4" â†’ ("ç‰", 4)
        "ã‚»6" â†’ ("ã‚»", 6)
    """
    if not sex_age_str:
        return (None, None)

    sex = sex_age_str[0] if len(sex_age_str) >= 1 else None
    age_str = sex_age_str[1:] if len(sex_age_str) >= 2 else None

    try:
        age = int(age_str)
    except:
        age = None

    return (sex, age)
```

### parse_horse_weight()

```python
def parse_horse_weight(weight_str: str) -> Tuple[Optional[int], Optional[int]]:
    """
    é¦¬ä½“é‡æ–‡å­—åˆ—ã‚’åˆ†è§£

    Examples:
        "476(+2)" â†’ (476, +2)
        "480(-4)" â†’ (480, -4)
        "è¨ˆä¸" â†’ (None, None)
        "é™¤å¤–" â†’ (None, None)
    """
    if not weight_str or weight_str in ['è¨ˆä¸', 'é™¤å¤–', '-']:
        return (None, None)

    # "476(+2)" ã‚’ãƒ‘ãƒ¼ã‚¹
    match = re.match(r'(\d+)\(([\+\-]?\d+)\)', weight_str)
    if match:
        weight = int(match.group(1))
        change = int(match.group(2))
        return (weight, change)

    # "476" ã®ã¿ï¼ˆå¢—æ¸›ãªã—ï¼‰
    match = re.match(r'(\d+)', weight_str)
    if match:
        weight = int(match.group(1))
        return (weight, 0)

    return (None, None)
```

---

## ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### SQLiteãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†

```python
import sqlite3

def save_parse_error(file_path: str, error_message: str, conn: sqlite3.Connection):
    """ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã‚’SQLiteã«è¨˜éŒ²"""
    cursor = conn.cursor()
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS parse_errors (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            file_path TEXT NOT NULL,
            error_message TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    """)

    cursor.execute("""
        INSERT INTO parse_errors (file_path, error_message)
        VALUES (?, ?)
    """, (file_path, error_message))

    conn.commit()
```

### ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã®ãƒ­ã‚°

```python
try:
    df = parse_results_html(file_path)
except Exception as e:
    logging.error(f"Parse failed: {file_path}, {e}", exc_info=True)
    save_parse_error(file_path, str(e), conn)
    return pd.DataFrame()  # ç©ºã®DataFrameã‚’è¿”ã™
```

---

## ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿å“è³ªæ”¹å–„ã®æ­´å²

### v1.0 â†’ v1.5ï¼ˆ2023-10ï¼‰

#### æ”¹å–„å†…å®¹

1. **HTMLãƒ‘ãƒ¼ã‚µãƒ¼ã®å¤‰æ›´**
   - `lxml` â†’ `html.parser`
   - ç†ç”±: lxmlã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¾å­˜æ€§ã€äº’æ›æ€§å•é¡Œ

2. **ãƒ¬ãƒ¼ã‚¹çµæœã®æ¬ æãƒ‡ãƒ¼ã‚¿å‰Šæ¸›**
   - Before: 10.2% missing
   - After: 0.0% missing
   - æ‰‹æ³•: 4æ®µéšãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

3. **æ–°è¦ã‚«ãƒ©ãƒ è¿½åŠ ï¼ˆ11å€‹ï¼‰**
   - race_name, distance_m, track_surface, weather, track_condition
   - venue, day_of_meeting, round_of_year
   - race_class, age_restriction, head_count

4. **trainer_id, owner_name ã®æŠ½å‡ºæ”¹å–„**
   - Before: 30% missing
   - After: 5% missing
   - æ‰‹æ³•: åˆ—æ•°ã«å¿œã˜ãŸæŸ”è»Ÿãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª¿æ•´

### v1.5 â†’ v2.0ï¼ˆ2025-11ï¼‰

#### æ”¹å–„å†…å®¹

1. **æ´¾ç”Ÿç‰¹å¾´é‡ã®è¿½åŠ **
   - pace_index, position_change_*, popularity_finish_diff
   - time_except_last3f, final_corner_to_finish

2. **horses_performance ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜**
   - Before: ãƒ‘ãƒ¼ã‚¹å‡¦ç†ã®ã¿ã€ä¿å­˜ãªã—
   - After: horses_performance.parquet ã¨ã—ã¦ä¿å­˜

3. **è¡€çµ±ãƒ‡ãƒ¼ã‚¿ã®æ‹¡å¼µ**
   - ancestor_birth_year, ancestor_coat_color è¿½åŠ 

---

**æ¬¡ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: [06_ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°.md](./06_ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°.md)
