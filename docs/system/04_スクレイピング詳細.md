# 04_ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è©³ç´°

**æœ€çµ‚æ›´æ–°æ—¥**: 2025-11-18

---

## ğŸ“‘ ç›®æ¬¡

1. [ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ¦‚è¦](#ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ¦‚è¦)
2. [å¯¾è±¡ã‚µã‚¤ãƒˆã¨å–å¾—ãƒ‡ãƒ¼ã‚¿](#å¯¾è±¡ã‚µã‚¤ãƒˆã¨å–å¾—ãƒ‡ãƒ¼ã‚¿)
3. [BANå¯¾ç­–æˆ¦ç•¥](#banå¯¾ç­–æˆ¦ç•¥)
4. [å®Ÿè£…è©³ç´°](#å®Ÿè£…è©³ç´°)
5. [ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°](#ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°)
6. [å®Ÿè¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«](#å®Ÿè¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«)

---

## ğŸŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ¦‚è¦

### ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹

| ã‚µã‚¤ãƒˆ | å–å¾—ãƒ‡ãƒ¼ã‚¿ | æ–¹æ³• | é »åº¦ |
|-------|----------|------|------|
| **netkeiba.com** | ãƒ¬ãƒ¼ã‚¹çµæœã€å‡ºé¦¬è¡¨ã€é¦¬ãƒ‡ãƒ¼ã‚¿ã€è¡€çµ± | requests + BeautifulSoup | æ—¥æ¬¡ |
| **JRAå…¬å¼** | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ªãƒƒã‚º | Selenium | ãƒ¬ãƒ¼ã‚¹ç›´å‰ |

### å–å¾—ãƒ—ãƒ­ã‚»ã‚¹

```
ã€Phase 0-1ã€‘ é–‹å‚¬æ—¥ç¨‹ã®å–å¾—
netkeiba.com/top/calendar.html
    â†“
kaisai_dates.csv (é–‹å‚¬æ—¥ãƒªã‚¹ãƒˆ)

ã€Phase 0-2ã€‘ ãƒ¬ãƒ¼ã‚¹IDãƒªã‚¹ãƒˆã®å–å¾—
netkeiba.com/race/list/{race_date}/
    â†“
race_id_list.csv (1æ—¥ã‚ãŸã‚Š50-100ãƒ¬ãƒ¼ã‚¹)

ã€Phase 0-3ã€‘ ãƒ¬ãƒ¼ã‚¹çµæœHTMLã®å–å¾—
FOR EACH race_id:
    netkeiba.com/race/{race_id}/
    â†“
    data/raw/html/race/{race_id}.bin

ã€Phase 0-4ã€‘ å‡ºé¦¬è¡¨HTMLã®å–å¾—
FOR EACH race_id:
    netkeiba.com/race/shutuba.html?race_id={race_id}
    â†“
    data/raw/html/shutuba/{race_id}.bin

ã€Phase 0-5ã€‘ é¦¬IDãƒªã‚¹ãƒˆã®æŠ½å‡º
FROM races.parquet:
    SELECT DISTINCT horse_id
    â†“
horse_id_list.txt

ã€Phase 0-6ã€‘ é¦¬ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«HTMLã®å–å¾—
FOR EACH horse_id:
    netkeiba.com/horse/{horse_id}/
    â†“
    data/raw/html/horse/{horse_id}_profile.bin

ã€Phase 0-7ã€‘ é¦¬éå»æˆç¸¾HTMLã®å–å¾—
FOR EACH horse_id:
    netkeiba.com/horse/ped/{horse_id}/
    â†“
    data/raw/html/horse/{horse_id}_perf.bin

ã€Phase 0-8ã€‘ è¡€çµ±HTMLã®å–å¾—
FOR EACH horse_id:
    netkeiba.com/horse/ped/{horse_id}/
    â†“
    data/raw/html/ped/{horse_id}.bin
```

---

## ğŸ¯ å¯¾è±¡ã‚µã‚¤ãƒˆã¨å–å¾—ãƒ‡ãƒ¼ã‚¿

### netkeiba.com

#### 1. ãƒ¬ãƒ¼ã‚¹çµæœãƒšãƒ¼ã‚¸

**URLå½¢å¼**: `https://db.netkeiba.com/race/{race_id}/`

**ä¾‹**: `https://db.netkeiba.com/race/202310010811/`

**å–å¾—ãƒ‡ãƒ¼ã‚¿**:
- ãƒ¬ãƒ¼ã‚¹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆè·é›¢ã€é¦¬å ´ã€å¤©å€™ã€ç«¶é¦¬å ´ï¼‰
- çµæœãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆç€é †ã€é¦¬åã€é¨æ‰‹ã€ã‚¿ã‚¤ãƒ ã€ã‚ªãƒƒã‚ºï¼‰
- æ‰•æˆ»é‡‘æƒ…å ±ï¼ˆå˜å‹ã€è¤‡å‹ã€é¦¬é€£ã€é¦¬å˜ã€ãƒ¯ã‚¤ãƒ‰ï¼‰

**HTMLæ§‹é€ **:
```html
<div class="data_intro">
    <div class="diary_snap_cut">
        <span>ãƒ€1200m / å¤©å€™:æ™´ / ãƒ€ãƒ¼ãƒˆ:è‰¯ / ç™ºèµ°:10:10</span>
    </div>
</div>

<table class="race_table_01">
    <tbody>
        <tr>
            <td>1</td>                    <!-- ç€é † -->
            <td>4</td>                    <!-- æ ç•ª -->
            <td>7</td>                    <!-- é¦¬ç•ª -->
            <td><a href="/horse/2020104567/">ã‚³ãƒ³ãƒˆãƒ¬ã‚¤ãƒ«</a></td>
            <td>ç‰¡3</td>                  <!-- æ€§é½¢ -->
            <td>57.0</td>                 <!-- æ–¤é‡ -->
            <td><a href="/jockey/01234/">ç¦æ°¸ç¥ä¸€</a></td>
            <td>2:23.3</td>               <!-- ã‚¿ã‚¤ãƒ  -->
            <td>-</td>                    <!-- ç€å·® -->
            <td>...</td>
        </tr>
    </tbody>
</table>
```

#### 2. å‡ºé¦¬è¡¨ãƒšãƒ¼ã‚¸

**URLå½¢å¼**: `https://race.netkeiba.com/race/shutuba.html?race_id={race_id}`

**å–å¾—ãƒ‡ãƒ¼ã‚¿**:
- å‡ºèµ°é¦¬ãƒªã‚¹ãƒˆ
- æœã‚ªãƒƒã‚ºã€æœäººæ°—
- ãƒ–ãƒªãƒ³ã‚«ãƒ¼ã€äºˆæƒ³å°

#### 3. é¦¬ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒšãƒ¼ã‚¸

**URLå½¢å¼**: `https://db.netkeiba.com/horse/{horse_id}/`

**å–å¾—ãƒ‡ãƒ¼ã‚¿**:
- ç”Ÿå¹´æœˆæ—¥ã€æ€§åˆ¥ã€æ¯›è‰²
- èª¿æ•™å¸«ã€é¦¬ä¸»ã€ç”Ÿç”£è€…
- é¦¬ä½“æƒ…å ±ï¼ˆä½“é«˜ã€èƒ¸å›²ã€ç®¡å›²ï¼‰

#### 4. é¦¬éå»æˆç¸¾ãƒšãƒ¼ã‚¸

**URLå½¢å¼**: `https://db.netkeiba.com/horse/result/{horse_id}/`

**å–å¾—ãƒ‡ãƒ¼ã‚¿**:
- å…¨ãƒ¬ãƒ¼ã‚¹å±¥æ­´
- å„ãƒ¬ãƒ¼ã‚¹ã®è©³ç´°ï¼ˆç€é †ã€ã‚¿ã‚¤ãƒ ã€ã‚ªãƒƒã‚ºï¼‰

#### 5. è¡€çµ±ãƒšãƒ¼ã‚¸

**URLå½¢å¼**: `https://db.netkeiba.com/horse/ped/{horse_id}/`

**å–å¾—ãƒ‡ãƒ¼ã‚¿**:
- 5ä¸–ä»£è¡€çµ±è¡¨
- å„å…ˆç¥–é¦¬ã®ç”Ÿå¹´ã€æ¯›è‰²

---

### JRAå…¬å¼ã‚µã‚¤ãƒˆ

**URL**: `https://www.jra.go.jp/JRADB/accessO.html`

**å–å¾—ãƒ‡ãƒ¼ã‚¿**:
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å˜å‹ã‚ªãƒƒã‚º
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¤‡å‹ã‚ªãƒƒã‚º
- ã‚ªãƒƒã‚ºæ›´æ–°æ™‚åˆ»

**æ–¹æ³•**: Seleniumï¼ˆå‹•çš„JavaScriptå®Ÿè¡ŒãŒå¿…è¦ï¼‰

---

## ğŸ›¡ï¸ BANå¯¾ç­–æˆ¦ç•¥

### 1. User-Agent ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³

```python
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
]

headers = {"User-Agent": random.choice(USER_AGENTS)}
```

### 2. ãƒ©ãƒ³ãƒ€ãƒ ã‚¹ãƒªãƒ¼ãƒ—

```python
import time
import random

MIN_SLEEP_SECONDS = 2.5
MAX_SLEEP_SECONDS = 5.0

sleep_time = random.uniform(MIN_SLEEP_SECONDS, MAX_SLEEP_SECONDS)
time.sleep(sleep_time)
```

**ç†ç”±**: äººé–“ã®ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¨¡å€£

### 3. HTTP 400 æ¤œå‡º â†’ ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³

```python
if response.status_code == 400:
    logger.critical(f"HTTP 400 Error. IP BANã®å¯èƒ½æ€§")
    time.sleep(60)  # 60ç§’å¾…æ©Ÿ
    return None
```

### 4. æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ãƒªãƒˆãƒ©ã‚¤

```python
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter

session = requests.Session()
retries = Retry(
    total=5,
    backoff_factor=0.5,  # 0.5, 1, 2, 4, 8ç§’
    status_forcelist=(500, 502, 503, 504, 429),
    allowed_methods={"GET", "POST"}
)
adapter = HTTPAdapter(max_retries=retries)
session.mount("http://", adapter)
session.mount("https://", adapter)
```

### 5. ä¸¦åˆ—å‡¦ç†ã®åˆ¶é™

```python
# âŒ NG: ä¸¦åˆ—ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆBANç¢ºå®Ÿï¼‰
with Pool(processes=10) as pool:
    pool.map(scrape_race, race_ids)

# âœ… OK: é€æ¬¡å®Ÿè¡Œ
for race_id in tqdm(race_ids):
    scrape_race(race_id)
    time.sleep(random.uniform(2.5, 5.0))
```

---

## ğŸ’» å®Ÿè£…è©³ç´°

### ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ (_scrape_html.py)

```python
def fetch_html_robust_get(
    url: str,
    session: Optional[requests.Session] = None,
    additional_headers: Optional[Dict[str, str]] = None
) -> Optional[bytes]:
    """
    å …ç‰¢ãªHTMLå–å¾—

    Returns:
        HTML content (bytes) or None if failed
    """
    if session is None:
        session = get_robust_session()

    try:
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚¹ãƒªãƒ¼ãƒ—
        sleep_time = random.uniform(MIN_SLEEP_SECONDS, MAX_SLEEP_SECONDS)
        time.sleep(sleep_time)

        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œ
        headers = {"User-Agent": random.choice(USER_AGENTS)}
        if additional_headers:
            headers.update(additional_headers)

        response = session.get(url, headers=headers, timeout=30)

        # HTTP 400å¯¾ç­–
        if response.status_code == 400:
            logger.critical(f"HTTP 400: {url}")
            time.sleep(60)
            return None

        response.raise_for_status()
        return response.content

    except requests.exceptions.RequestException as e:
        logger.error(f"Request failed: {url}, {e}")
        return None
```

### ãƒ¬ãƒ¼ã‚¹çµæœã®ãƒãƒƒãƒã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°

```python
def scrape_race_results(
    race_id_list: List[str],
    output_dir: Path,
    session: Optional[requests.Session] = None
):
    """ãƒ¬ãƒ¼ã‚¹çµæœã®ãƒãƒƒãƒã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""

    if session is None:
        session = get_robust_session()

    output_dir.mkdir(parents=True, exist_ok=True)

    success_count = 0
    fail_count = 0

    for race_id in tqdm(race_id_list, desc="Scraping race results"):
        output_file = output_dir / f"{race_id}.bin"

        # æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
        if output_file.exists():
            logger.info(f"Already exists: {race_id}")
            continue

        # URLæ§‹ç¯‰
        url = f"https://db.netkeiba.com/race/{race_id}/"

        # HTMLå–å¾—
        html_bytes = fetch_html_robust_get(url, session)

        if html_bytes:
            # EUC-JPãƒã‚¤ãƒŠãƒªã¨ã—ã¦ä¿å­˜
            with open(output_file, 'wb') as f:
                f.write(html_bytes)
            success_count += 1
        else:
            fail_count += 1
            logger.warning(f"Failed to scrape: {race_id}")

    logger.info(f"Scraping complete: {success_count} success, {fail_count} failed")
```

### JRAã‚ªãƒƒã‚ºå–å¾—ï¼ˆSeleniumï¼‰

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

def scrape_jra_odds(race_id: str) -> Dict:
    """
    JRAãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ªãƒƒã‚ºå–å¾—
    """
    driver = webdriver.Chrome()

    try:
        # JRA ODDSç”»é¢ã¸
        url = f"https://www.jra.go.jp/JRADB/accessO.html"
        driver.get(url)

        # ãƒ¬ãƒ¼ã‚¹é¸æŠï¼ˆJavaScriptæ“ä½œï¼‰
        wait = WebDriverWait(driver, 30)
        race_select = wait.until(
            EC.presence_of_element_located((By.ID, "raceSelect"))
        )
        race_select.send_keys(race_id)

        # ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«å¾…æ©Ÿ
        odds_table = wait.until(
            EC.presence_of_element_located((By.CLASS_NAME, "oddsTable"))
        )

        # ãƒ‘ãƒ¼ã‚¹
        rows = odds_table.find_elements(By.TAG_NAME, "tr")
        odds_data = {}

        for row in rows:
            cells = row.find_elements(By.TAG_NAME, "td")
            if len(cells) >= 3:
                horse_number = cells[0].text
                win_odds = cells[1].text
                place_odds = cells[2].text

                odds_data[horse_number] = {
                    'win_odds': float(win_odds),
                    'place_odds': place_odds
                }

        return odds_data

    finally:
        driver.quit()
```

---

## ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### 1. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼

```python
try:
    response = session.get(url, timeout=30)
except requests.exceptions.Timeout:
    logger.error(f"Timeout: {url}")
    # ãƒªãƒˆãƒ©ã‚¤ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
    retry_queue.append(url)
except requests.exceptions.ConnectionError:
    logger.error(f"Connection error: {url}")
    time.sleep(10)  # 10ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤
```

### 2. HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ©ãƒ¼

```python
if response.status_code == 404:
    logger.warning(f"Page not found: {url}")
    # ãƒ¬ãƒ¼ã‚¹æœªé–‹å‚¬ã®å¯èƒ½æ€§ â†’ ã‚¹ã‚­ãƒƒãƒ—

elif response.status_code == 400:
    logger.critical(f"HTTP 400 (IP BAN): {url}")
    time.sleep(60)  # 60ç§’ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³

elif response.status_code == 503:
    logger.error(f"Service unavailable: {url}")
    time.sleep(30)  # 30ç§’å¾…æ©Ÿ
```

### 3. ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼

```python
try:
    soup = BeautifulSoup(html_text, 'html.parser')
    result_table = soup.find('table', class_='race_table_01')

    if not result_table:
        raise ValueError("Result table not found")

except Exception as e:
    logger.error(f"Parse error: {file_path}, {e}")
    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’SQLiteã«è¨˜éŒ²
    save_parse_error(file_path, str(e))
```

---

## ğŸ“… å®Ÿè¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

### æ—¥æ¬¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆCronè¨­å®šä¾‹ï¼‰

```bash
# /etc/crontab

# æ·±å¤œ3:00 - å‰æ—¥ãƒ¬ãƒ¼ã‚¹çµæœã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
0 3 * * * cd /path/to/KeibaAI_v2 && python run_scraping_pipeline_local.py

# æ·±å¤œ4:00 - HTML â†’ Parquet ãƒ‘ãƒ¼ã‚¹
0 4 * * * cd /path/to/KeibaAI_v2 && python run_parsing_pipeline_local.py

# æ·±å¤œ4:30 - ç‰¹å¾´é‡ç”Ÿæˆ
30 4 * * * cd /path/to/KeibaAI_v2 && python src/features/generate_features.py

# æœ10:00 - å½“æ—¥ãƒ¬ãƒ¼ã‚¹äºˆæ¸¬
0 10 * * * cd /path/to/KeibaAI_v2 && python src/models/predict.py --date $(date +%Y-%m-%d)

# ãƒ¬ãƒ¼ã‚¹10åˆ†å‰ - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œï¼ˆæ‰‹å‹•ãƒˆãƒªã‚¬ãƒ¼æ¨å¥¨ï¼‰
# python src/sim/simulate_daily_races.py --date $(date +%Y-%m-%d)
```

### é€±æ¬¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

```bash
# æ—¥æ›œå¤œ23:00 - ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´
0 23 * * 0 cd /path/to/KeibaAI_v2 && python src/models/train_mu_model.py
```

---

## ğŸ“Š ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµ±è¨ˆ

### å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ï¼ˆå‚è€ƒï¼‰

| æœŸé–“ | ãƒ¬ãƒ¼ã‚¹æ•° | HTMLå–å¾—æ•° | ã‚¨ãƒ©ãƒ¼ç‡ | æ‰€è¦æ™‚é–“ |
|-----|---------|----------|---------|---------|
| 2023-01 | 3,456 | 3,450 | 0.17% | 4æ™‚é–“12åˆ† |
| 2023-02 | 3,124 | 3,118 | 0.19% | 3æ™‚é–“48åˆ† |
| 2023-03 | 3,689 | 3,680 | 0.24% | 4æ™‚é–“35åˆ† |

### ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ

- **å¹³å‡å–å¾—é€Ÿåº¦**: 3.5ç§’/ãƒšãƒ¼ã‚¸ï¼ˆã‚¹ãƒªãƒ¼ãƒ—è¾¼ã¿ï¼‰
- **1æ—¥ã‚ãŸã‚Š**: ç´„14,400ãƒšãƒ¼ã‚¸ï¼ˆ24æ™‚é–“ãƒ•ãƒ«ç¨¼åƒæ™‚ï¼‰
- **æ¨å¥¨é€Ÿåº¦**: 6ç§’/ãƒšãƒ¼ã‚¸ï¼ˆBANå›é¿ã®ãŸã‚ï¼‰

---

**æ¬¡ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: [05_ãƒ‘ãƒ¼ã‚¹å‡¦ç†è©³ç´°.md](./05_ãƒ‘ãƒ¼ã‚¹å‡¦ç†è©³ç´°.md)
