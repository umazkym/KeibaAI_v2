#!/usr/bin/env python3
"""
ãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ05: é¦¬ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«HTMLã®æ§‹é€ ç¢ºèª
è¡€çµ±æƒ…å ±ãŒå–å¾—ã§ããªã„åŸå› ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã€HTMLã®æ§‹é€ ã‚’ç›´æ¥ç¢ºèª
"""

from pathlib import Path
from bs4 import BeautifulSoup
import re

def analyze_horse_profile_html(file_path: Path):
    """é¦¬ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«HTMLã‚’è©³ç´°åˆ†æ"""
    print("=" * 80)
    print(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«: {file_path.name}")
    print("=" * 80)

    with open(file_path, 'rb') as f:
        html_bytes = f.read()

    try:
        html_text = html_bytes.decode('euc_jp', errors='replace')
    except:
        html_text = html_bytes.decode('utf-8', errors='replace')

    soup = BeautifulSoup(html_text, 'html.parser')

    # 1. é¦¬åã®ç¢ºèª
    print("\nğŸ“Œ 1. é¦¬åã®ç¢ºèª")
    horse_title = soup.find('div', class_='horse_title')
    if horse_title:
        h1 = horse_title.find('h1')
        if h1:
            print(f"   âœ… é¦¬å: {h1.get_text(strip=True)}")
        else:
            print(f"   âš ï¸ h1ã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        print(f"   âŒ horse_title ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    # 2. ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèª
    print("\nğŸ“Œ 2. ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèª")
    profile_table = soup.find('table', class_='db_prof_table')
    if profile_table:
        print(f"   âœ… db_prof_table ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        rows = profile_table.find_all('tr')
        print(f"   è¡Œæ•°: {len(rows)}")

        for i, row in enumerate(rows[:10], 1):  # æœ€åˆã®10è¡Œ
            th = row.find('th')
            td = row.find('td')
            if th and td:
                label = th.get_text(strip=True)
                value = td.get_text(strip=True)[:50]  # æœ€åˆã®50æ–‡å­—
                print(f"     {i:>2}. {label:15s}: {value}")
    else:
        print(f"   âŒ db_prof_table ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    # 3. è¡€çµ±ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèªï¼ˆé‡è¦ï¼‰
    print("\nğŸ“Œ 3. è¡€çµ±ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèªï¼ˆblood_tableï¼‰")
    blood_table = soup.find('table', class_='blood_table')
    if blood_table:
        print(f"   âœ… blood_table ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼")
        rows = blood_table.find_all('tr')
        print(f"   è¡Œæ•°: {len(rows)}")

        for i, row in enumerate(rows, 1):
            print(f"\n   --- è¡Œ {i} ---")
            td = row.find('td')
            if td:
                # ãƒªãƒ³ã‚¯ã‚’æ¢ã™
                links = td.find_all('a', href=re.compile(r'/horse/'))
                print(f"     ãƒªãƒ³ã‚¯æ•°: {len(links)}")
                for j, link in enumerate(links, 1):
                    horse_name = link.get_text(strip=True)
                    href = link.get('href', '')
                    horse_id_match = re.search(r'/horse/(\w+)', href)
                    horse_id = horse_id_match.group(1) if horse_id_match else 'N/A'
                    print(f"       {j}. åå‰: {horse_name:20s} | ID: {horse_id}")
            else:
                print(f"     tdã‚¿ã‚°ãªã—")
    else:
        print(f"   âŒ blood_table ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # ä»£æ›¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
        print(f"\n   ğŸ’¡ ä»£æ›¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ç´¢...")

        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: è¡€çµ±æƒ…å ±ã‚’å«ã‚€ä»–ã®ãƒ†ãƒ¼ãƒ–ãƒ«
        all_tables = soup.find_all('table')
        print(f"   å…¨ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(all_tables)}")

        for i, table in enumerate(all_tables, 1):
            table_class = table.get('class', [])
            table_id = table.get('id', '')
            print(f"     {i}. class={table_class}, id={table_id}")

            # 'è¡€çµ±' ã¨ã„ã†ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€ã‹ç¢ºèª
            if 'è¡€çµ±' in table.get_text() or 'pedigree' in str(table_class).lower():
                print(f"       â†’ è¡€çµ±æƒ…å ±ã®å¯èƒ½æ€§ã‚ã‚Šï¼")

                # ã“ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ§‹é€ ã‚’è©³ã—ãè¦‹ã‚‹
                rows = table.find_all('tr')[:3]  # æœ€åˆã®3è¡Œ
                for j, row in enumerate(rows, 1):
                    cells = row.find_all(['th', 'td'])
                    cell_texts = [cell.get_text(strip=True)[:30] for cell in cells]
                    print(f"         è¡Œ{j}: {cell_texts}")

    # 4. è¡€çµ±æƒ…å ±ã‚’å«ã‚€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å…¨æ¢ç´¢
    print("\nğŸ“Œ 4. ã€Œçˆ¶ã€ã€Œæ¯ã€ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆã®æ¢ç´¢")
    text_content = soup.get_text()

    if 'çˆ¶' in text_content:
        print(f"   âœ… 'çˆ¶' ã¨ã„ã†æ–‡å­—åˆ—ãŒå­˜åœ¨ã—ã¾ã™")
        # çˆ¶ã®å‘¨è¾ºãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        idx = text_content.find('çˆ¶')
        surrounding = text_content[max(0, idx-20):min(len(text_content), idx+100)]
        print(f"   å‘¨è¾ºãƒ†ã‚­ã‚¹ãƒˆ: {surrounding.strip()[:200]}")
    else:
        print(f"   âš ï¸ 'çˆ¶' ã¨ã„ã†æ–‡å­—åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    if 'æ¯' in text_content:
        print(f"   âœ… 'æ¯' ã¨ã„ã†æ–‡å­—åˆ—ãŒå­˜åœ¨ã—ã¾ã™")
        # æ¯ã®å‘¨è¾ºãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        idx = text_content.find('æ¯')
        surrounding = text_content[max(0, idx-20):min(len(text_content), idx+100)]
        print(f"   å‘¨è¾ºãƒ†ã‚­ã‚¹ãƒˆ: {surrounding.strip()[:200]}")
    else:
        print(f"   âš ï¸ 'æ¯' ã¨ã„ã†æ–‡å­—åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    # 5. ã™ã¹ã¦ã®ãƒªãƒ³ã‚¯ã‹ã‚‰ /horse/ ã‚’å«ã‚€ã‚‚ã®ã‚’æŠ½å‡º
    print("\nğŸ“Œ 5. ã™ã¹ã¦ã® /horse/ ãƒªãƒ³ã‚¯ã‚’æŠ½å‡º")
    all_horse_links = soup.find_all('a', href=re.compile(r'/horse/'))
    print(f"   /horse/ ãƒªãƒ³ã‚¯æ•°: {len(all_horse_links)}")

    if len(all_horse_links) > 0:
        print(f"   æœ€åˆã®10ä»¶:")
        for i, link in enumerate(all_horse_links[:10], 1):
            horse_name = link.get_text(strip=True)
            href = link.get('href', '')
            horse_id_match = re.search(r'/horse/(\w+)', href)
            horse_id = horse_id_match.group(1) if horse_id_match else 'N/A'

            # è¦ªè¦ç´ ã®ã‚¿ã‚°ã¨ã‚¯ãƒ©ã‚¹ã‚’ç¢ºèª
            parent = link.parent
            parent_tag = parent.name if parent else 'N/A'
            parent_class = parent.get('class', []) if parent else []

            print(f"     {i:>2}. {horse_name:20s} | ID: {horse_id:15s} | è¦ª: <{parent_tag}> {parent_class}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\n")
    print("ğŸ” KeibaAI_v2 é¦¬ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«HTMLæ§‹é€ åˆ†æ")
    print("\n")

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’3ä»¶åˆ†æ
    raw_horse_dir = Path("keibaai/data/raw/html/horse")
    profile_files = sorted([f for f in raw_horse_dir.glob("*_profile.bin")])[:3]

    if not profile_files:
        print("âŒ ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return

    for file in profile_files:
        analyze_horse_profile_html(file)
        print("\n")

    print("=" * 80)
    print("ğŸ“‹ åˆ†æå®Œäº†")
    print("=" * 80)
    print("\nğŸ’¡ æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
    print("  1. blood_tableãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ â†’ åˆ¥ã®HTMLæ§‹é€ ã‚’ç¢ºèª")
    print("  2. ä»£æ›¿ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆ â†’ ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä¿®æ­£")
    print("\n")

if __name__ == "__main__":
    main()
