# Keiba AI プロジェクト進捗レポート

## 1. はじめに

本ドキュメントは、AI競馬予測システムの開発プロジェクトにおける、初期評価から問題特定、および修正に至るまでの一連の進捗をまとめたものです。

## 2. 初期評価と問題の特定 (2025-11-14)

プロジェクトの初期段階として、学習済みモデル（`mu_model_v2`）の性能を評価するため、`keibaai/src/models/evaluate_model.py`スクリプトを実行しました。

### 2.1. 確認された事象

1.  **多数の警告:** 実行時に`pyarrow`のデータ読み込み警告、Pandasの`SettingWithCopyWarning`および`FutureWarning`が多数発生し、コードの堅牢性に問題があることが示唆されました。
2.  **モデル性能の低さ:**
    *   タイム予測モデル（Regressor）のRMSE（平均二乗誤差平方根）が約22秒と、予測モデルとして機能していないレベルの大きな誤差が確認されました。
    *   順位予測モデル（Ranker）の性能を示すスピアマン順位相関係数が、期待される負の値ではなく、**正の値（約`+0.15`）**を示しました。これは、モデルが「スコアが高いほど良い順位」と予測すべきところを、「スコアが高いほど悪い順位」と完全に逆の相関関係を学習してしまっていることを意味していました。

これらの結果から、**モデルの予測能力に深刻な問題がある**ことが判明しました。

## 3. デバッグと原因分析の過程

モデル性能の低さの根本原因を特定するため、以下のステップで詳細な調査を実施しました。

### 3.1. Step 1: スクリプトの警告解消

まず、コードの安定性を確保するため、評価スクリプトで発生していた各種警告を解消しました。

*   `data_utils.py`: `pyarrow`の警告を解消するため、データ読み込みロジックをより堅牢な方式に修正。
*   `evaluate_model.py`: `SettingWithCopyWarning`と`FutureWarning`を解消するため、DataFrameの操作をより安全な方法に修正。

**結果:** 警告は解消されましたが、モデルの性能（相関係数が正の値）は改善されませんでした。これにより、問題が表面的なバグではなく、より根深い箇所にあることが確認されました。

### 3.2. Step 2: モデル実装の検証

次に、モデルのロジック自体に誤りがないかを確認するため、`keibaai/src/models/model_train.py`に実装されている`MuEstimator`クラスと、プロジェクトの仕様書を比較検証しました。

**結果:** モデルクラスの実装は仕様書に忠実であり、スコア計算のロジックに明らかな誤りは見つかりませんでした。しかし、この過程で、スコアの正規化処理がレース単位ではなくバッチ全体で行われている問題を発見し、レース単位の正規化に修正しました。それでもなお、モデル性能は改善しませんでした。

### 3.3. Step 3: 特徴量分析 (根本原因の発見)

モデルや評価ロジックが正しいと仮定し、入力データである**特徴量**に問題があるとの仮説を立て、`notebooks/02_feature_analysis.ipynb`を作成して特徴量と着順の相関分析を実施しました。

**分析結果:**

1.  **特徴量の欠落:** `prize_total`（獲得賞金）や`morning_odds`（前日オッズ）といった、予測に不可欠なはずの重要特徴量がすべて`NaN`（欠損値）となっており、モデルに全く利用されていないことが判明しました。
2.  **相関の逆転:** `past_..._finish_time_seconds_mean`（過去の平均タイム）が、着順と負の相関（速い馬ほど着順が悪い）を示しており、直感に反する誤った関係性を持っていることが確認されました。
3.  **予測能力の低さ:** 全体的に、各特徴量と着順との相関係数が極めて低く（多くが`0.1`未満）、現在の特徴量セットではモデルが有効な学習を行うことが困難であることが示唆されました。

### 3.4. 根本原因の特定

特徴量欠落の原因をさらに追跡した結果、`keibaai/src/modules/parsers/shutuba_parser.py`（出馬表パーサー）が、仕様として`prize_total`等の情報を**意図的に取得しない設計**になっていることが判明しました。これらの情報は出馬表ページには存在せず、馬の過去成績ページなど、別のページから取得する必要があったのです。

最終的に、**「特徴量生成パイプライン（`feature_engine.py`）が、別ページから取得すべき重要な特徴量（獲得賞金、戦績など）を考慮せず、不完全なデータセットで特徴量を生成していた」**ことが、モデル性能の低さの根本原因であると特定しました。

## 4. 実施した修正

根本原因を解決するため、`keibaai/src/features/feature_engine.py`に対して以下の大規模な修正を実施しました。

1.  **`_add_horse_history_features`メソッドの新規実装:**
    馬の過去の全レース結果（`results_history_df`）を動的に集計し、これまで欠落していた`prize_total`（通算獲得賞金）、`career_starts`（通算出走回数）、`career_wins`（通算勝利数）といった**時点ごとの累計特徴量**を正しく計算するロジックを新規に実装しました。この実装は、将来のデータを含めないよう（リークしないよう）、各レース時点での過去の成績のみを集計する堅牢な設計になっています。

2.  **`_add_past_performance_features`メソッドのバグ修正:**
    同様に、過去N走の成績を集計する既存のロジックにも、データが正しく紐付けられない重大なバグが存在したため、これもリーク対策を施した新しいロジックに全面的に置換しました。

これらの修正により、特徴量生成パイプラインは、これまで欠落・破損していた重要な特徴量を正しく生成できる状態になりました。

## 5. 現状と今後のステップ



**現状:**

*   特徴量生成パイプラインの重大なバグが修正され、コードは正常に動作する状態です。

*   修正されたロジックで、2023年のデータを対象に特徴量の再生成が完了しました。



**今後のステップ:**

既存のモデル（`mu_model_v2`）は、バグのあった不正確な特徴量で学習されたものであるため、無効です。したがって、以下のステップでモデルを再構築し、性能改善を確認する必要があります。



1.  **モデルの再学習（Next Step）:**

    新しく生成した正しい特徴量データを使い、`train_mu_model.py`を実行してモデルを再学習させ、新しいバージョン（`mu_model_v4`）を作成します。



2.  **新モデルの評価:**

    再学習させた`mu_model_v4`を`evaluate_model.py`で評価し、スピアマン相関係数が期待通り**負の値**を示し、かつその絶対値が改善されるかを確認します。



3.  **`SettingWithCopyWarning`の修正:**

    モデルの再学習が成功した後、`train_mu_model.py`に残っている`SettingWithCopyWarning`を修正し、コードの品質をさらに向上させます。



## 6. データ品質の詳細調査 (2025-11-14〜)



### 6.1. 仮説



特徴量生成ロジックのバグを修正したにもかかわらず、モデル性能が全く改善されないことから、問題の根本原因はさらに上流の**データソース**にある可能性が高いと判断。



**仮説：** パーサーによってHTMLから抽出された「パース済みデータ」の段階で、重要なカラムが`Null`または空になっている。これにより、後続の特徴量生成が意味のある値を作り出せず、結果としてモデルが有効な学習を行えていない。



### 6.2. 調査計画







この仮説を検証するため、新しい分析ノートブック `notebooks/03_data_quality_analysis.ipynb` を作成し、以下の調査を実施する。







1.  **パース済みデータの網羅的な読み込み:** `keibaai/data/parsed/parquet/` ディレクトリ内の主要なデータ（`races`, `shutuba`, `horses`など）をすべて読み込む。



2.  **欠損率の算出:** 各データフレームの全カラムに対し、欠損値（`Null`）の割合をパーセンテージで算出する。



3.  **問題点の特定:** 欠損率が異常に高いカラムを特定し、どの情報がパイプラインから欠落しているかを明確にする。



4.  **原因の深掘り:** 特定された問題カラムについて、担当するパーサーのロジックを再検証し、「HTMLにデータが存在するにも関わらず抽出できていない」のか、「元々HTMLにデータが存在しない」のかを切り分ける。



5.  **進捗の記録:** 本`PROGRESS.md`に、分析の過程と発見した事実を逐一記録する。







### 6.3. データ品質調査の結果と結論







上記計画に基づき、`03_data_quality_analysis.ipynb` を実行し、パース済みデータの品質を調査した結果、モデル性能の低さの根本原因が完全に明らかになった。







**衝撃的な分析結果:**







1.  **`races` (レース結果) データ:**



    *   `prize_money` (獲得賞金): **63.7%が欠損**。モデルの目的変数の一つであり、馬の能力を測る上で極めて重要なこのデータが、大半のレースで取得できていない。







2.  **`shutuba` (出馬表) データ:**



    *   `prize_total` (生涯獲得賞金), `morning_odds` (前日オッズ), `morning_popularity` (前日人気), `career_starts` (通算出走回数), `career_wins` (通算勝利数) など、**予測に不可欠な特徴量が軒並み100%欠損**している。







3.  **`horses` (馬プロフィール) データ:**



    *   `trainer_id` (調教師ID) が**58.4%欠損**。



    *   `birth_date` (誕生日) を含むその他基本情報も**約50%が欠損**。







**結論：根本原因は「パーサー」の不備によるデータ枯渇**







モデル性能が低い真の原因は、特徴量生成やモデルのロジックのバグではなく、そのさらに上流である**パーサー群 (`results_parser`, `shutuba_parser`, `horse_info_parser`) が、HTMLソースから必要な情報を正しく抽出できていない**ことにあった。







これにより、後続のプロセスは**ほぼ空っぽのデータ**を引き渡され、意味のある特徴量を作れず、結果としてモデルは何も学習できていなかった。これまでの修正は、いわば「燃料が全く無いエンジン」を調整しようとしていたに等しい。







**次のステップ：**



全ての作業の焦点を、**パーサーのデバッグと修正**に切り替える。まずは最も影響の大きい `races` データの `prize_money` 欠損を解消するため、`results_parser.py` の調査から開始する。




